{"metadata":{"availableInstances":[{"_defaultOrder":0,"_isFastLaunch":true,"category":"General purpose","gpuNum":0,"hideHardwareSpecs":false,"memoryGiB":4,"name":"ml.t3.medium","vcpuNum":2},{"_defaultOrder":1,"_isFastLaunch":false,"category":"General purpose","gpuNum":0,"hideHardwareSpecs":false,"memoryGiB":8,"name":"ml.t3.large","vcpuNum":2},{"_defaultOrder":2,"_isFastLaunch":false,"category":"General purpose","gpuNum":0,"hideHardwareSpecs":false,"memoryGiB":16,"name":"ml.t3.xlarge","vcpuNum":4},{"_defaultOrder":3,"_isFastLaunch":false,"category":"General purpose","gpuNum":0,"hideHardwareSpecs":false,"memoryGiB":32,"name":"ml.t3.2xlarge","vcpuNum":8},{"_defaultOrder":4,"_isFastLaunch":true,"category":"General purpose","gpuNum":0,"hideHardwareSpecs":false,"memoryGiB":8,"name":"ml.m5.large","vcpuNum":2},{"_defaultOrder":5,"_isFastLaunch":false,"category":"General purpose","gpuNum":0,"hideHardwareSpecs":false,"memoryGiB":16,"name":"ml.m5.xlarge","vcpuNum":4},{"_defaultOrder":6,"_isFastLaunch":false,"category":"General purpose","gpuNum":0,"hideHardwareSpecs":false,"memoryGiB":32,"name":"ml.m5.2xlarge","vcpuNum":8},{"_defaultOrder":7,"_isFastLaunch":false,"category":"General purpose","gpuNum":0,"hideHardwareSpecs":false,"memoryGiB":64,"name":"ml.m5.4xlarge","vcpuNum":16},{"_defaultOrder":8,"_isFastLaunch":false,"category":"General purpose","gpuNum":0,"hideHardwareSpecs":false,"memoryGiB":128,"name":"ml.m5.8xlarge","vcpuNum":32},{"_defaultOrder":9,"_isFastLaunch":false,"category":"General purpose","gpuNum":0,"hideHardwareSpecs":false,"memoryGiB":192,"name":"ml.m5.12xlarge","vcpuNum":48},{"_defaultOrder":10,"_isFastLaunch":false,"category":"General purpose","gpuNum":0,"hideHardwareSpecs":false,"memoryGiB":256,"name":"ml.m5.16xlarge","vcpuNum":64},{"_defaultOrder":11,"_isFastLaunch":false,"category":"General purpose","gpuNum":0,"hideHardwareSpecs":false,"memoryGiB":384,"name":"ml.m5.24xlarge","vcpuNum":96},{"_defaultOrder":12,"_isFastLaunch":false,"category":"General purpose","gpuNum":0,"hideHardwareSpecs":false,"memoryGiB":8,"name":"ml.m5d.large","vcpuNum":2},{"_defaultOrder":13,"_isFastLaunch":false,"category":"General purpose","gpuNum":0,"hideHardwareSpecs":false,"memoryGiB":16,"name":"ml.m5d.xlarge","vcpuNum":4},{"_defaultOrder":14,"_isFastLaunch":false,"category":"General purpose","gpuNum":0,"hideHardwareSpecs":false,"memoryGiB":32,"name":"ml.m5d.2xlarge","vcpuNum":8},{"_defaultOrder":15,"_isFastLaunch":false,"category":"General purpose","gpuNum":0,"hideHardwareSpecs":false,"memoryGiB":64,"name":"ml.m5d.4xlarge","vcpuNum":16},{"_defaultOrder":16,"_isFastLaunch":false,"category":"General purpose","gpuNum":0,"hideHardwareSpecs":false,"memoryGiB":128,"name":"ml.m5d.8xlarge","vcpuNum":32},{"_defaultOrder":17,"_isFastLaunch":false,"category":"General purpose","gpuNum":0,"hideHardwareSpecs":false,"memoryGiB":192,"name":"ml.m5d.12xlarge","vcpuNum":48},{"_defaultOrder":18,"_isFastLaunch":false,"category":"General purpose","gpuNum":0,"hideHardwareSpecs":false,"memoryGiB":256,"name":"ml.m5d.16xlarge","vcpuNum":64},{"_defaultOrder":19,"_isFastLaunch":false,"category":"General purpose","gpuNum":0,"hideHardwareSpecs":false,"memoryGiB":384,"name":"ml.m5d.24xlarge","vcpuNum":96},{"_defaultOrder":20,"_isFastLaunch":false,"category":"General purpose","gpuNum":0,"hideHardwareSpecs":true,"memoryGiB":0,"name":"ml.geospatial.interactive","supportedImageNames":["sagemaker-geospatial-v1-0"],"vcpuNum":0},{"_defaultOrder":21,"_isFastLaunch":true,"category":"Compute optimized","gpuNum":0,"hideHardwareSpecs":false,"memoryGiB":4,"name":"ml.c5.large","vcpuNum":2},{"_defaultOrder":22,"_isFastLaunch":false,"category":"Compute optimized","gpuNum":0,"hideHardwareSpecs":false,"memoryGiB":8,"name":"ml.c5.xlarge","vcpuNum":4},{"_defaultOrder":23,"_isFastLaunch":false,"category":"Compute optimized","gpuNum":0,"hideHardwareSpecs":false,"memoryGiB":16,"name":"ml.c5.2xlarge","vcpuNum":8},{"_defaultOrder":24,"_isFastLaunch":false,"category":"Compute optimized","gpuNum":0,"hideHardwareSpecs":false,"memoryGiB":32,"name":"ml.c5.4xlarge","vcpuNum":16},{"_defaultOrder":25,"_isFastLaunch":false,"category":"Compute optimized","gpuNum":0,"hideHardwareSpecs":false,"memoryGiB":72,"name":"ml.c5.9xlarge","vcpuNum":36},{"_defaultOrder":26,"_isFastLaunch":false,"category":"Compute optimized","gpuNum":0,"hideHardwareSpecs":false,"memoryGiB":96,"name":"ml.c5.12xlarge","vcpuNum":48},{"_defaultOrder":27,"_isFastLaunch":false,"category":"Compute optimized","gpuNum":0,"hideHardwareSpecs":false,"memoryGiB":144,"name":"ml.c5.18xlarge","vcpuNum":72},{"_defaultOrder":28,"_isFastLaunch":false,"category":"Compute optimized","gpuNum":0,"hideHardwareSpecs":false,"memoryGiB":192,"name":"ml.c5.24xlarge","vcpuNum":96},{"_defaultOrder":29,"_isFastLaunch":true,"category":"Accelerated computing","gpuNum":1,"hideHardwareSpecs":false,"memoryGiB":16,"name":"ml.g4dn.xlarge","vcpuNum":4},{"_defaultOrder":30,"_isFastLaunch":false,"category":"Accelerated computing","gpuNum":1,"hideHardwareSpecs":false,"memoryGiB":32,"name":"ml.g4dn.2xlarge","vcpuNum":8},{"_defaultOrder":31,"_isFastLaunch":false,"category":"Accelerated computing","gpuNum":1,"hideHardwareSpecs":false,"memoryGiB":64,"name":"ml.g4dn.4xlarge","vcpuNum":16},{"_defaultOrder":32,"_isFastLaunch":false,"category":"Accelerated computing","gpuNum":1,"hideHardwareSpecs":false,"memoryGiB":128,"name":"ml.g4dn.8xlarge","vcpuNum":32},{"_defaultOrder":33,"_isFastLaunch":false,"category":"Accelerated computing","gpuNum":4,"hideHardwareSpecs":false,"memoryGiB":192,"name":"ml.g4dn.12xlarge","vcpuNum":48},{"_defaultOrder":34,"_isFastLaunch":false,"category":"Accelerated computing","gpuNum":1,"hideHardwareSpecs":false,"memoryGiB":256,"name":"ml.g4dn.16xlarge","vcpuNum":64},{"_defaultOrder":35,"_isFastLaunch":false,"category":"Accelerated computing","gpuNum":1,"hideHardwareSpecs":false,"memoryGiB":61,"name":"ml.p3.2xlarge","vcpuNum":8},{"_defaultOrder":36,"_isFastLaunch":false,"category":"Accelerated computing","gpuNum":4,"hideHardwareSpecs":false,"memoryGiB":244,"name":"ml.p3.8xlarge","vcpuNum":32},{"_defaultOrder":37,"_isFastLaunch":false,"category":"Accelerated computing","gpuNum":8,"hideHardwareSpecs":false,"memoryGiB":488,"name":"ml.p3.16xlarge","vcpuNum":64},{"_defaultOrder":38,"_isFastLaunch":false,"category":"Accelerated computing","gpuNum":8,"hideHardwareSpecs":false,"memoryGiB":768,"name":"ml.p3dn.24xlarge","vcpuNum":96},{"_defaultOrder":39,"_isFastLaunch":false,"category":"Memory Optimized","gpuNum":0,"hideHardwareSpecs":false,"memoryGiB":16,"name":"ml.r5.large","vcpuNum":2},{"_defaultOrder":40,"_isFastLaunch":false,"category":"Memory Optimized","gpuNum":0,"hideHardwareSpecs":false,"memoryGiB":32,"name":"ml.r5.xlarge","vcpuNum":4},{"_defaultOrder":41,"_isFastLaunch":false,"category":"Memory Optimized","gpuNum":0,"hideHardwareSpecs":false,"memoryGiB":64,"name":"ml.r5.2xlarge","vcpuNum":8},{"_defaultOrder":42,"_isFastLaunch":false,"category":"Memory Optimized","gpuNum":0,"hideHardwareSpecs":false,"memoryGiB":128,"name":"ml.r5.4xlarge","vcpuNum":16},{"_defaultOrder":43,"_isFastLaunch":false,"category":"Memory Optimized","gpuNum":0,"hideHardwareSpecs":false,"memoryGiB":256,"name":"ml.r5.8xlarge","vcpuNum":32},{"_defaultOrder":44,"_isFastLaunch":false,"category":"Memory Optimized","gpuNum":0,"hideHardwareSpecs":false,"memoryGiB":384,"name":"ml.r5.12xlarge","vcpuNum":48},{"_defaultOrder":45,"_isFastLaunch":false,"category":"Memory Optimized","gpuNum":0,"hideHardwareSpecs":false,"memoryGiB":512,"name":"ml.r5.16xlarge","vcpuNum":64},{"_defaultOrder":46,"_isFastLaunch":false,"category":"Memory Optimized","gpuNum":0,"hideHardwareSpecs":false,"memoryGiB":768,"name":"ml.r5.24xlarge","vcpuNum":96},{"_defaultOrder":47,"_isFastLaunch":false,"category":"Accelerated computing","gpuNum":1,"hideHardwareSpecs":false,"memoryGiB":16,"name":"ml.g5.xlarge","vcpuNum":4},{"_defaultOrder":48,"_isFastLaunch":false,"category":"Accelerated computing","gpuNum":1,"hideHardwareSpecs":false,"memoryGiB":32,"name":"ml.g5.2xlarge","vcpuNum":8},{"_defaultOrder":49,"_isFastLaunch":false,"category":"Accelerated computing","gpuNum":1,"hideHardwareSpecs":false,"memoryGiB":64,"name":"ml.g5.4xlarge","vcpuNum":16},{"_defaultOrder":50,"_isFastLaunch":false,"category":"Accelerated computing","gpuNum":1,"hideHardwareSpecs":false,"memoryGiB":128,"name":"ml.g5.8xlarge","vcpuNum":32},{"_defaultOrder":51,"_isFastLaunch":false,"category":"Accelerated computing","gpuNum":1,"hideHardwareSpecs":false,"memoryGiB":256,"name":"ml.g5.16xlarge","vcpuNum":64},{"_defaultOrder":52,"_isFastLaunch":false,"category":"Accelerated computing","gpuNum":4,"hideHardwareSpecs":false,"memoryGiB":192,"name":"ml.g5.12xlarge","vcpuNum":48},{"_defaultOrder":53,"_isFastLaunch":false,"category":"Accelerated computing","gpuNum":4,"hideHardwareSpecs":false,"memoryGiB":384,"name":"ml.g5.24xlarge","vcpuNum":96},{"_defaultOrder":54,"_isFastLaunch":false,"category":"Accelerated computing","gpuNum":8,"hideHardwareSpecs":false,"memoryGiB":768,"name":"ml.g5.48xlarge","vcpuNum":192},{"_defaultOrder":55,"_isFastLaunch":false,"category":"Accelerated computing","gpuNum":8,"hideHardwareSpecs":false,"memoryGiB":1152,"name":"ml.p4d.24xlarge","vcpuNum":96},{"_defaultOrder":56,"_isFastLaunch":false,"category":"Accelerated computing","gpuNum":8,"hideHardwareSpecs":false,"memoryGiB":1152,"name":"ml.p4de.24xlarge","vcpuNum":96}],"colab":{"name":"Fine-tune a language model","provenance":[]},"instance_type":"ml.m5.2xlarge","kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"vscode":{"interpreter":{"hash":"aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"}},"kaggle":{"accelerator":"gpu","dataSources":[],"dockerImageVersionId":30627,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Fine-Tune a Generative AI Model for text to code generation","metadata":{"tags":[]}},{"cell_type":"markdown","source":"In this notebook, you will fine-tune an existing LLM from Hugging Face for code generation. We use the [FLAN-T5](https://huggingface.co/docs/transformers/model_doc/flan-t5) model, which provides a high quality instruction tuned model and can generate python code out of the box. We will explore a PEFT fine-tuning approach and evaluate the results with ROUGE metrics. ","metadata":{}},{"cell_type":"markdown","source":"## Installing necessary packages","metadata":{}},{"cell_type":"markdown","source":"Now install the required packages for the LLM and datasets.","metadata":{"tags":[]}},{"cell_type":"code","source":"import torch\n\n# Ensure the model uses GPU\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nprint(device)","metadata":{"execution":{"iopub.status.busy":"2023-12-28T08:34:20.453011Z","iopub.execute_input":"2023-12-28T08:34:20.453860Z","iopub.status.idle":"2023-12-28T08:34:21.943772Z","shell.execute_reply.started":"2023-12-28T08:34:20.453826Z","shell.execute_reply":"2023-12-28T08:34:21.942836Z"},"trusted":true},"execution_count":5,"outputs":[{"name":"stdout","text":"cuda\n","output_type":"stream"}]},{"cell_type":"code","source":"!pip install -q torch\n!pip install -q torchdata\n\n!pip install -q transformers\n!pip install -q datasets\n!pip install -q evaluate\n!pip install -q rouge_score\n!pip install -q loralib\n!pip install -q peft\n!pip install -q pandas pyarrow\n!pip install -q pandas fastparquet\n!pip install -q scikit-learn","metadata":{"execution":{"iopub.status.busy":"2023-12-28T08:34:21.945671Z","iopub.execute_input":"2023-12-28T08:34:21.946172Z","iopub.status.idle":"2023-12-28T08:36:40.820279Z","shell.execute_reply.started":"2023-12-28T08:34:21.946122Z","shell.execute_reply":"2023-12-28T08:36:40.819135Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"code","source":"from torch.utils.data import Dataset, DataLoader","metadata":{"execution":{"iopub.status.busy":"2023-12-28T08:36:40.822248Z","iopub.execute_input":"2023-12-28T08:36:40.822575Z","iopub.status.idle":"2023-12-28T08:36:40.827640Z","shell.execute_reply.started":"2023-12-28T08:36:40.822547Z","shell.execute_reply":"2023-12-28T08:36:40.826681Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"code","source":"from datasets import load_dataset\nfrom transformers import AutoModelForSeq2SeqLM, AutoTokenizer, GenerationConfig, TrainingArguments, Trainer\nimport torch\nimport time\nimport evaluate\nimport pandas as pd\nimport numpy as np","metadata":{"execution":{"iopub.status.busy":"2023-12-28T08:36:40.828624Z","iopub.execute_input":"2023-12-28T08:36:40.828898Z","iopub.status.idle":"2023-12-28T08:36:55.873499Z","shell.execute_reply.started":"2023-12-28T08:36:40.828878Z","shell.execute_reply":"2023-12-28T08:36:55.871975Z"},"trusted":true},"execution_count":8,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/scipy/__init__.py:146: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.24.3\n  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n","output_type":"stream"}]},{"cell_type":"markdown","source":"## Loading the base model - FlanT5-base","metadata":{}},{"cell_type":"code","source":"model_name='google/flan-t5-base'\n\noriginal_model = AutoModelForSeq2SeqLM.from_pretrained(model_name, torch_dtype=torch.bfloat16)\ntokenizer = AutoTokenizer.from_pretrained(model_name)","metadata":{"execution":{"iopub.status.busy":"2023-12-28T08:36:55.876398Z","iopub.execute_input":"2023-12-28T08:36:55.877315Z","iopub.status.idle":"2023-12-28T08:37:05.367001Z","shell.execute_reply.started":"2023-12-28T08:36:55.877273Z","shell.execute_reply":"2023-12-28T08:37:05.366196Z"},"trusted":true},"execution_count":9,"outputs":[{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/1.40k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"b5574726c6aa43c499ac117ef4aabaa3"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model.safetensors:   0%|          | 0.00/990M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"a0f018aa954940f29b126942de4e02aa"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"generation_config.json:   0%|          | 0.00/147 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"480fadc0e0934aa9a1003d03c660b9c2"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer_config.json:   0%|          | 0.00/2.54k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"04565dd6bf3d4c6f82dd16c7647c5189"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"spiece.model:   0%|          | 0.00/792k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"710e2b6d12064f98aea236931add0a3c"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer.json:   0%|          | 0.00/2.42M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"d6511c7fcf914db98a735d346b8b338a"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"special_tokens_map.json:   0%|          | 0.00/2.20k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"8bba9c6118c0491c8475d4a7f5c22803"}},"metadata":{}}]},{"cell_type":"markdown","source":"## Loading the training data","metadata":{}},{"cell_type":"code","source":"!git lfs install\n!git clone https://huggingface.co/datasets/iamtarun/python_code_instructions_18k_alpaca","metadata":{"execution":{"iopub.status.busy":"2023-12-28T08:37:05.368205Z","iopub.execute_input":"2023-12-28T08:37:05.368510Z","iopub.status.idle":"2023-12-28T08:37:11.188662Z","shell.execute_reply.started":"2023-12-28T08:37:05.368485Z","shell.execute_reply":"2023-12-28T08:37:11.187388Z"},"trusted":true},"execution_count":10,"outputs":[{"name":"stdout","text":"Git LFS initialized.\nCloning into 'python_code_instructions_18k_alpaca'...\nremote: Enumerating objects: 30, done.\u001b[K\nremote: Counting objects: 100% (1/1), done.\u001b[K\nremote: Total 30 (delta 0), reused 0 (delta 0), pack-reused 29\u001b[K\nUnpacking objects: 100% (30/30), 4.41 KiB | 645.00 KiB/s, done.\n","output_type":"stream"}]},{"cell_type":"code","source":"parquet_file_path = '/kaggle/working/python_code_instructions_18k_alpaca/data/train-00000-of-00001-8b6e212f3e1ece96.parquet'\n\n# Load the Parquet file as a Pandas DataFrame\ndf = pd.read_parquet(parquet_file_path)\n\n# Now df is a Pandas DataFrame containing the data from the Parquet file\n","metadata":{"execution":{"iopub.status.busy":"2023-12-28T08:37:11.190875Z","iopub.execute_input":"2023-12-28T08:37:11.191392Z","iopub.status.idle":"2023-12-28T08:37:11.472523Z","shell.execute_reply.started":"2023-12-28T08:37:11.191338Z","shell.execute_reply":"2023-12-28T08:37:11.471643Z"},"trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"code","source":"df","metadata":{"execution":{"iopub.status.busy":"2023-12-28T08:37:11.473726Z","iopub.execute_input":"2023-12-28T08:37:11.474032Z","iopub.status.idle":"2023-12-28T08:37:11.627477Z","shell.execute_reply.started":"2023-12-28T08:37:11.474006Z","shell.execute_reply":"2023-12-28T08:37:11.626389Z"},"trusted":true},"execution_count":12,"outputs":[{"execution_count":12,"output_type":"execute_result","data":{"text/plain":"                                             instruction  \\\n0      Create a function to calculate the sum of a se...   \n1      Generate a Python code for crawling a website ...   \n2      Create a Python list comprehension to get the ...   \n3       Generate a python script to perform this action.   \n4      Write a python script to generates random numb...   \n...                                                  ...   \n18607  Generate a loop in Python which iterates throu...   \n18608  Can you design a function in Python to sort a ...   \n18609  Generate a Python function to search an array ...   \n18610  Develop an HTTP API in Python to retrieve the ...   \n18611  Create a classification algorithm in Python to...   \n\n                                                   input  \\\n0                                        [1, 2, 3, 4, 5]   \n1      website: www.example.com \\ndata to crawl: phon...   \n2                                                          \n3      Given a string, remove all the consecutive dup...   \n4                                                          \n...                                                  ...   \n18607                                                      \n18608           tuples = [(\"b\", 0), (\"a\", 1), (\"c\", -1)]   \n18609            Array = [1, 5, 10, 15, 20], Target = 15   \n18610                                                      \n18611                                                      \n\n                                                  output  \\\n0      # Python code\\ndef sum_sequence(sequence):\\n  ...   \n1      import requests\\nimport re\\n\\ndef crawl_websit...   \n2                     [x*x for x in [1, 2, 3, 5, 8, 13]]   \n3      def remove_duplicates(string): \\n    result = ...   \n4      def generate_random_divisible_number():\\n    i...   \n...                                                  ...   \n18607     for value in list_of_values:\\n    print(value)   \n18608  def sort_tuple(tuples):\\n    # sort by 2nd ite...   \n18609  def search(array, target):\\n # Iterate over ar...   \n18610  import requests\\nfrom bs4 import BeautifulSoup...   \n18611  # Import Python libraries\\nimport numpy as np\\...   \n\n                                                  prompt  \n0      Below is an instruction that describes a task....  \n1      Below is an instruction that describes a task....  \n2      Below is an instruction that describes a task....  \n3      Below is an instruction that describes a task....  \n4      Below is an instruction that describes a task....  \n...                                                  ...  \n18607  Below is an instruction that describes a task....  \n18608  Below is an instruction that describes a task....  \n18609  Below is an instruction that describes a task....  \n18610  Below is an instruction that describes a task....  \n18611  Below is an instruction that describes a task....  \n\n[18612 rows x 4 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>instruction</th>\n      <th>input</th>\n      <th>output</th>\n      <th>prompt</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>Create a function to calculate the sum of a se...</td>\n      <td>[1, 2, 3, 4, 5]</td>\n      <td># Python code\\ndef sum_sequence(sequence):\\n  ...</td>\n      <td>Below is an instruction that describes a task....</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>Generate a Python code for crawling a website ...</td>\n      <td>website: www.example.com \\ndata to crawl: phon...</td>\n      <td>import requests\\nimport re\\n\\ndef crawl_websit...</td>\n      <td>Below is an instruction that describes a task....</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>Create a Python list comprehension to get the ...</td>\n      <td></td>\n      <td>[x*x for x in [1, 2, 3, 5, 8, 13]]</td>\n      <td>Below is an instruction that describes a task....</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>Generate a python script to perform this action.</td>\n      <td>Given a string, remove all the consecutive dup...</td>\n      <td>def remove_duplicates(string): \\n    result = ...</td>\n      <td>Below is an instruction that describes a task....</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>Write a python script to generates random numb...</td>\n      <td></td>\n      <td>def generate_random_divisible_number():\\n    i...</td>\n      <td>Below is an instruction that describes a task....</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>18607</th>\n      <td>Generate a loop in Python which iterates throu...</td>\n      <td></td>\n      <td>for value in list_of_values:\\n    print(value)</td>\n      <td>Below is an instruction that describes a task....</td>\n    </tr>\n    <tr>\n      <th>18608</th>\n      <td>Can you design a function in Python to sort a ...</td>\n      <td>tuples = [(\"b\", 0), (\"a\", 1), (\"c\", -1)]</td>\n      <td>def sort_tuple(tuples):\\n    # sort by 2nd ite...</td>\n      <td>Below is an instruction that describes a task....</td>\n    </tr>\n    <tr>\n      <th>18609</th>\n      <td>Generate a Python function to search an array ...</td>\n      <td>Array = [1, 5, 10, 15, 20], Target = 15</td>\n      <td>def search(array, target):\\n # Iterate over ar...</td>\n      <td>Below is an instruction that describes a task....</td>\n    </tr>\n    <tr>\n      <th>18610</th>\n      <td>Develop an HTTP API in Python to retrieve the ...</td>\n      <td></td>\n      <td>import requests\\nfrom bs4 import BeautifulSoup...</td>\n      <td>Below is an instruction that describes a task....</td>\n    </tr>\n    <tr>\n      <th>18611</th>\n      <td>Create a classification algorithm in Python to...</td>\n      <td></td>\n      <td># Import Python libraries\\nimport numpy as np\\...</td>\n      <td>Below is an instruction that describes a task....</td>\n    </tr>\n  </tbody>\n</table>\n<p>18612 rows × 4 columns</p>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"print(df.iloc[0]['prompt'])","metadata":{"execution":{"iopub.status.busy":"2023-12-28T14:11:26.676274Z","iopub.execute_input":"2023-12-28T14:11:26.676900Z","iopub.status.idle":"2023-12-28T14:11:26.681816Z","shell.execute_reply.started":"2023-12-28T14:11:26.676865Z","shell.execute_reply":"2023-12-28T14:11:26.680855Z"},"trusted":true},"execution_count":169,"outputs":[{"name":"stdout","text":"Below is an instruction that describes a task. Write a response that appropriately completes the request.\n\n### Instruction:\nCreate a function to calculate the sum of a sequence of integers.\n\n### Input:\n[1, 2, 3, 4, 5]\n\n### Output:\n# Python code\ndef sum_sequence(sequence):\n  sum = 0\n  for num in sequence:\n    sum += num\n  return sum\n","output_type":"stream"}]},{"cell_type":"code","source":"original_model.to(device)","metadata":{"execution":{"iopub.status.busy":"2023-12-28T14:58:55.529664Z","iopub.execute_input":"2023-12-28T14:58:55.530333Z","iopub.status.idle":"2023-12-28T14:58:55.546317Z","shell.execute_reply.started":"2023-12-28T14:58:55.530297Z","shell.execute_reply":"2023-12-28T14:58:55.545495Z"},"collapsed":true,"jupyter":{"outputs_hidden":true},"trusted":true},"execution_count":172,"outputs":[{"execution_count":172,"output_type":"execute_result","data":{"text/plain":"T5ForConditionalGeneration(\n  (shared): Embedding(32128, 768)\n  (encoder): T5Stack(\n    (embed_tokens): Embedding(32128, 768)\n    (block): ModuleList(\n      (0): T5Block(\n        (layer): ModuleList(\n          (0): T5LayerSelfAttention(\n            (SelfAttention): T5Attention(\n              (q): Linear(in_features=768, out_features=768, bias=False)\n              (k): Linear(in_features=768, out_features=768, bias=False)\n              (v): Linear(in_features=768, out_features=768, bias=False)\n              (o): Linear(in_features=768, out_features=768, bias=False)\n              (relative_attention_bias): Embedding(32, 12)\n            )\n            (layer_norm): T5LayerNorm()\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n          (1): T5LayerFF(\n            (DenseReluDense): T5DenseGatedActDense(\n              (wi_0): Linear(in_features=768, out_features=2048, bias=False)\n              (wi_1): Linear(in_features=768, out_features=2048, bias=False)\n              (wo): Linear(in_features=2048, out_features=768, bias=False)\n              (dropout): Dropout(p=0.1, inplace=False)\n              (act): NewGELUActivation()\n            )\n            (layer_norm): T5LayerNorm()\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n        )\n      )\n      (1-11): 11 x T5Block(\n        (layer): ModuleList(\n          (0): T5LayerSelfAttention(\n            (SelfAttention): T5Attention(\n              (q): Linear(in_features=768, out_features=768, bias=False)\n              (k): Linear(in_features=768, out_features=768, bias=False)\n              (v): Linear(in_features=768, out_features=768, bias=False)\n              (o): Linear(in_features=768, out_features=768, bias=False)\n            )\n            (layer_norm): T5LayerNorm()\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n          (1): T5LayerFF(\n            (DenseReluDense): T5DenseGatedActDense(\n              (wi_0): Linear(in_features=768, out_features=2048, bias=False)\n              (wi_1): Linear(in_features=768, out_features=2048, bias=False)\n              (wo): Linear(in_features=2048, out_features=768, bias=False)\n              (dropout): Dropout(p=0.1, inplace=False)\n              (act): NewGELUActivation()\n            )\n            (layer_norm): T5LayerNorm()\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n        )\n      )\n    )\n    (final_layer_norm): T5LayerNorm()\n    (dropout): Dropout(p=0.1, inplace=False)\n  )\n  (decoder): T5Stack(\n    (embed_tokens): Embedding(32128, 768)\n    (block): ModuleList(\n      (0): T5Block(\n        (layer): ModuleList(\n          (0): T5LayerSelfAttention(\n            (SelfAttention): T5Attention(\n              (q): Linear(in_features=768, out_features=768, bias=False)\n              (k): Linear(in_features=768, out_features=768, bias=False)\n              (v): Linear(in_features=768, out_features=768, bias=False)\n              (o): Linear(in_features=768, out_features=768, bias=False)\n              (relative_attention_bias): Embedding(32, 12)\n            )\n            (layer_norm): T5LayerNorm()\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n          (1): T5LayerCrossAttention(\n            (EncDecAttention): T5Attention(\n              (q): Linear(in_features=768, out_features=768, bias=False)\n              (k): Linear(in_features=768, out_features=768, bias=False)\n              (v): Linear(in_features=768, out_features=768, bias=False)\n              (o): Linear(in_features=768, out_features=768, bias=False)\n            )\n            (layer_norm): T5LayerNorm()\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n          (2): T5LayerFF(\n            (DenseReluDense): T5DenseGatedActDense(\n              (wi_0): Linear(in_features=768, out_features=2048, bias=False)\n              (wi_1): Linear(in_features=768, out_features=2048, bias=False)\n              (wo): Linear(in_features=2048, out_features=768, bias=False)\n              (dropout): Dropout(p=0.1, inplace=False)\n              (act): NewGELUActivation()\n            )\n            (layer_norm): T5LayerNorm()\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n        )\n      )\n      (1-11): 11 x T5Block(\n        (layer): ModuleList(\n          (0): T5LayerSelfAttention(\n            (SelfAttention): T5Attention(\n              (q): Linear(in_features=768, out_features=768, bias=False)\n              (k): Linear(in_features=768, out_features=768, bias=False)\n              (v): Linear(in_features=768, out_features=768, bias=False)\n              (o): Linear(in_features=768, out_features=768, bias=False)\n            )\n            (layer_norm): T5LayerNorm()\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n          (1): T5LayerCrossAttention(\n            (EncDecAttention): T5Attention(\n              (q): Linear(in_features=768, out_features=768, bias=False)\n              (k): Linear(in_features=768, out_features=768, bias=False)\n              (v): Linear(in_features=768, out_features=768, bias=False)\n              (o): Linear(in_features=768, out_features=768, bias=False)\n            )\n            (layer_norm): T5LayerNorm()\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n          (2): T5LayerFF(\n            (DenseReluDense): T5DenseGatedActDense(\n              (wi_0): Linear(in_features=768, out_features=2048, bias=False)\n              (wi_1): Linear(in_features=768, out_features=2048, bias=False)\n              (wo): Linear(in_features=2048, out_features=768, bias=False)\n              (dropout): Dropout(p=0.1, inplace=False)\n              (act): NewGELUActivation()\n            )\n            (layer_norm): T5LayerNorm()\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n        )\n      )\n    )\n    (final_layer_norm): T5LayerNorm()\n    (dropout): Dropout(p=0.1, inplace=False)\n  )\n  (lm_head): Linear(in_features=768, out_features=32128, bias=False)\n)"},"metadata":{}}]},{"cell_type":"code","source":"prompt = f\"\"\"What is the color of sky?\"\"\"\ninput_ids = tokenizer(prompt, return_tensors=\"pt\", truncation=True,).input_ids.to(device)\n# with torch.inference_mode():\noutput_ids = original_model.generate(input_ids=input_ids, generation_config=GenerationConfig(max_new_tokens=200, num_beams=1))\noutputs = tokenizer.decode(output_ids[0], skip_special_tokens=True)\nprint(f\"Prompt:\\n{prompt}\\n\")\nprint(f\"Generated instruction:\\n{outputs}\")","metadata":{"execution":{"iopub.status.busy":"2023-12-28T14:59:03.217717Z","iopub.execute_input":"2023-12-28T14:59:03.218199Z","iopub.status.idle":"2023-12-28T14:59:03.284764Z","shell.execute_reply.started":"2023-12-28T14:59:03.218143Z","shell.execute_reply":"2023-12-28T14:59:03.283882Z"},"trusted":true},"execution_count":173,"outputs":[{"name":"stdout","text":"Prompt:\nWhat is the color of sky?\n\nGenerated instruction:\nblue\n","output_type":"stream"}]},{"cell_type":"code","source":"def postprocess(text):\n    # Replace special tokens with actual escape characters\n    text = text.replace('four_spaces>', '    ')\n    text = text.replace('newline>', '\\n')\n    text = text.replace('tab>', '\\t')\n    return text\n\ndef preprocess(text):\n    # Replace '\\n' and '\\t' with unique tokens\n    text = text.replace('    ', '<four_spaces>')\n    text = text.replace('\\n', '<newline>')\n    text = text.replace('\\t', '<tab>')\n    return text\n\n# Apply preprocessing to your DataFrame\n# df['processed_output'] = df['output'].apply(preprocess)\n\n\ndef tokenize_function(row,max_input_tokens = 256):\n    \n    # Preparing the instruction input\n    row_input = f\"\"\"\n    Below is an instruction that describes a task. Write a response that appropriately completes the request.\n    \n    ### Instruction: \n    {row['instruction']}\n    \n    ### Input:\n    {row['input']}\n    \n    ### Response:\n    \"\"\"\n    \n    row_output = preprocess(row['output'])\n    \n    # Tokenize input without truncation to check the length\n    inputs = tokenizer(row_input, return_tensors=\"pt\")\n    labels = tokenizer(row_output, return_tensors=\"pt\")\n\n    # Check if tokenized input exceeds max_input_tokens\n    if len(inputs['input_ids'][0]) > max_input_tokens or len(labels['input_ids'][0]) > max_input_tokens:\n        # Ignore this input by returning None\n        return None\n    \n    # Tokenize input and labels\n    inputs = tokenizer(row_input, padding=\"max_length\", truncation=True, max_length=max_input_tokens, return_tensors=\"pt\")\n    labels = tokenizer(row_output, padding=\"max_length\", truncation=True, max_length=max_input_tokens, return_tensors=\"pt\")\n    \n    # Return tokenized inputs and labels\n    return {\n        'input_ids': inputs.input_ids, \n        'attention_mask': inputs.attention_mask, \n        'labels': labels.input_ids\n    }\n\n# Assuming df is your DataFrame with columns 'input' and 'labels'\n# Apply the tokenization function to each row\ntokenized_data = df.apply(lambda row: tokenize_function(row), axis=1)\n\ntokenized_data = tokenized_data.dropna()","metadata":{"execution":{"iopub.status.busy":"2023-12-28T08:37:11.628765Z","iopub.execute_input":"2023-12-28T08:37:11.629065Z","iopub.status.idle":"2023-12-28T08:37:52.595825Z","shell.execute_reply.started":"2023-12-28T08:37:11.629040Z","shell.execute_reply":"2023-12-28T08:37:52.595041Z"},"trusted":true},"execution_count":13,"outputs":[{"name":"stderr","text":"Token indices sequence length is longer than the specified maximum sequence length for this model (629 > 512). Running this sequence through the model will result in indexing errors\n","output_type":"stream"}]},{"cell_type":"markdown","source":"### Zero shot inference","metadata":{}},{"cell_type":"code","source":"row = df.iloc[1]\ntokenized_row = tokenize_function(row)","metadata":{"execution":{"iopub.status.busy":"2023-12-27T04:25:18.102763Z","iopub.execute_input":"2023-12-27T04:25:18.103188Z","iopub.status.idle":"2023-12-27T04:25:18.109053Z","shell.execute_reply.started":"2023-12-27T04:25:18.103160Z","shell.execute_reply":"2023-12-27T04:25:18.108243Z"},"trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"code","source":"row_input = f\"\"\"\nBelow is an instruction that describes a task. Write a response that appropriately completes the request.\n\n### Instruction: \n{row['instruction']}\n\n### Input:\n{row['input']}\n\n### Response:\n\"\"\"\ninput_ids = tokenizer(row_input, return_tensors=\"pt\").input_ids\n# with torch.inference_mode():\noutput_ids = original_model.generate(input_ids=input_ids, generation_config=GenerationConfig(max_new_tokens=200, num_beams=1))\noutputs = tokenizer.decode(output_ids[0], skip_special_tokens=True)\noutput_postproc = postprocess(outputs)\n\nprint('---------------------------------------')\nprint(row_input)\nprint('---------------------------------------')\nprint(f\"Generated instruction:\\n{output_postproc}\")","metadata":{"execution":{"iopub.status.busy":"2023-12-27T04:25:18.110278Z","iopub.execute_input":"2023-12-27T04:25:18.110628Z","iopub.status.idle":"2023-12-27T04:25:18.902882Z","shell.execute_reply.started":"2023-12-27T04:25:18.110593Z","shell.execute_reply":"2023-12-27T04:25:18.901861Z"},"trusted":true},"execution_count":12,"outputs":[{"name":"stdout","text":"---------------------------------------\n\nBelow is an instruction that describes a task. Write a response that appropriately completes the request.\n\n### Instruction: \nGenerate a Python code for crawling a website for a specific type of data.\n\n### Input:\nwebsite: www.example.com \ndata to crawl: phone numbers\n\n### Response:\n\n---------------------------------------\nGenerated instruction:\nI've put that in the \"phone numbers\" section.\n","output_type":"stream"}]},{"cell_type":"code","source":"row = df.iloc[3]\ntokenized_row = tokenize_function(row)","metadata":{"execution":{"iopub.status.busy":"2023-12-27T04:25:18.904098Z","iopub.execute_input":"2023-12-27T04:25:18.904390Z","iopub.status.idle":"2023-12-27T04:25:18.910242Z","shell.execute_reply.started":"2023-12-27T04:25:18.904364Z","shell.execute_reply":"2023-12-27T04:25:18.909325Z"},"trusted":true},"execution_count":13,"outputs":[]},{"cell_type":"code","source":"row_input = f\"\"\"\nBelow is an instruction that describes a task. Write a response that appropriately completes the request.\n\n### Instruction: \n{row['instruction']}\n\n### Input:\n{row['input']}\n\n### Response:\n\"\"\"\ninput_ids = tokenizer(row_input, return_tensors=\"pt\").input_ids\n# with torch.inference_mode():\noutput_ids = original_model.generate(input_ids=input_ids, generation_config=GenerationConfig(max_new_tokens=200, num_beams=1))\noutputs = tokenizer.decode(output_ids[0], skip_special_tokens=True)\noutput_postproc = postprocess(outputs)\n\nprint('---------------------------------------')\nprint(row_input)\nprint('---------------------------------------')\nprint(f\"Generated instruction:\\n{output_postproc}\")\nprint('---------------------------------------')\nprint(f\"Baseline or expected output code:\\n{row['output']}\")","metadata":{"execution":{"iopub.status.busy":"2023-12-27T04:25:18.911626Z","iopub.execute_input":"2023-12-27T04:25:18.911987Z","iopub.status.idle":"2023-12-27T04:25:19.758592Z","shell.execute_reply.started":"2023-12-27T04:25:18.911962Z","shell.execute_reply":"2023-12-27T04:25:19.757614Z"},"trusted":true},"execution_count":14,"outputs":[{"name":"stdout","text":"---------------------------------------\n\nBelow is an instruction that describes a task. Write a response that appropriately completes the request.\n\n### Instruction: \nGenerate a python script to perform this action.\n\n### Input:\nGiven a string, remove all the consecutive duplicates from the string.\n\nInput: \"AAABBCCCD\"\n\n### Response:\n\n---------------------------------------\nGenerated instruction:\naabccd='AABBCCCD'\n---------------------------------------\nBaseline or expected output code:\ndef remove_duplicates(string): \n    result = \"\" \n    prev = '' \n\n    for char in string:\n        if char != prev: \n            result += char\n            prev = char\n    return result\n\nresult = remove_duplicates(\"AAABBCCCD\")\nprint(result)\n","output_type":"stream"}]},{"cell_type":"markdown","source":"### Splitting the data for training","metadata":{}},{"cell_type":"code","source":"from sklearn.model_selection import train_test_split\n\n# Assuming 'df' is your DataFrame\n\n# Splitting the dataset into training and a combined validation & test set\ntrain_df, val_test_df = train_test_split(tokenized_data, test_size=0.3, random_state=42)\n\n# Splitting the combined validation & test set into separate validation and test sets\nval_df, test_df = train_test_split(val_test_df, test_size=0.5, random_state=42)\n\n# Now, train_df, val_df, and test_df are your training, validation, and test sets respectively","metadata":{"execution":{"iopub.status.busy":"2023-12-28T08:37:52.597017Z","iopub.execute_input":"2023-12-28T08:37:52.597336Z","iopub.status.idle":"2023-12-28T08:37:52.618068Z","shell.execute_reply.started":"2023-12-28T08:37:52.597311Z","shell.execute_reply":"2023-12-28T08:37:52.617051Z"},"trusted":true},"execution_count":14,"outputs":[]},{"cell_type":"code","source":"# Splitting the dataset into training and a combined validation & test set\ntrain_df_raw, val_test_df_raw = train_test_split(df, test_size=0.3, random_state=42)\n\n# Splitting the combined validation & test set into separate validation and test sets\nval_df_raw, test_df_raw = train_test_split(val_test_df, test_size=0.5, random_state=42)","metadata":{"execution":{"iopub.status.busy":"2023-12-28T09:41:49.957832Z","iopub.execute_input":"2023-12-28T09:41:49.958251Z","iopub.status.idle":"2023-12-28T09:41:49.971279Z","shell.execute_reply.started":"2023-12-28T09:41:49.958224Z","shell.execute_reply":"2023-12-28T09:41:49.970351Z"},"trusted":true},"execution_count":50,"outputs":[]},{"cell_type":"code","source":"df","metadata":{"execution":{"iopub.status.busy":"2023-12-28T09:45:11.078630Z","iopub.execute_input":"2023-12-28T09:45:11.079814Z","iopub.status.idle":"2023-12-28T09:45:11.095097Z","shell.execute_reply.started":"2023-12-28T09:45:11.079769Z","shell.execute_reply":"2023-12-28T09:45:11.094083Z"},"trusted":true},"execution_count":54,"outputs":[{"execution_count":54,"output_type":"execute_result","data":{"text/plain":"                                             instruction  \\\n0      Create a function to calculate the sum of a se...   \n1      Generate a Python code for crawling a website ...   \n2      Create a Python list comprehension to get the ...   \n3       Generate a python script to perform this action.   \n4      Write a python script to generates random numb...   \n...                                                  ...   \n18607  Generate a loop in Python which iterates throu...   \n18608  Can you design a function in Python to sort a ...   \n18609  Generate a Python function to search an array ...   \n18610  Develop an HTTP API in Python to retrieve the ...   \n18611  Create a classification algorithm in Python to...   \n\n                                                   input  \\\n0                                        [1, 2, 3, 4, 5]   \n1      website: www.example.com \\ndata to crawl: phon...   \n2                                                          \n3      Given a string, remove all the consecutive dup...   \n4                                                          \n...                                                  ...   \n18607                                                      \n18608           tuples = [(\"b\", 0), (\"a\", 1), (\"c\", -1)]   \n18609            Array = [1, 5, 10, 15, 20], Target = 15   \n18610                                                      \n18611                                                      \n\n                                                  output  \\\n0      # Python code\\ndef sum_sequence(sequence):\\n  ...   \n1      import requests\\nimport re\\n\\ndef crawl_websit...   \n2                     [x*x for x in [1, 2, 3, 5, 8, 13]]   \n3      def remove_duplicates(string): \\n    result = ...   \n4      def generate_random_divisible_number():\\n    i...   \n...                                                  ...   \n18607     for value in list_of_values:\\n    print(value)   \n18608  def sort_tuple(tuples):\\n    # sort by 2nd ite...   \n18609  def search(array, target):\\n # Iterate over ar...   \n18610  import requests\\nfrom bs4 import BeautifulSoup...   \n18611  # Import Python libraries\\nimport numpy as np\\...   \n\n                                                  prompt  \n0      Below is an instruction that describes a task....  \n1      Below is an instruction that describes a task....  \n2      Below is an instruction that describes a task....  \n3      Below is an instruction that describes a task....  \n4      Below is an instruction that describes a task....  \n...                                                  ...  \n18607  Below is an instruction that describes a task....  \n18608  Below is an instruction that describes a task....  \n18609  Below is an instruction that describes a task....  \n18610  Below is an instruction that describes a task....  \n18611  Below is an instruction that describes a task....  \n\n[18612 rows x 4 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>instruction</th>\n      <th>input</th>\n      <th>output</th>\n      <th>prompt</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>Create a function to calculate the sum of a se...</td>\n      <td>[1, 2, 3, 4, 5]</td>\n      <td># Python code\\ndef sum_sequence(sequence):\\n  ...</td>\n      <td>Below is an instruction that describes a task....</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>Generate a Python code for crawling a website ...</td>\n      <td>website: www.example.com \\ndata to crawl: phon...</td>\n      <td>import requests\\nimport re\\n\\ndef crawl_websit...</td>\n      <td>Below is an instruction that describes a task....</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>Create a Python list comprehension to get the ...</td>\n      <td></td>\n      <td>[x*x for x in [1, 2, 3, 5, 8, 13]]</td>\n      <td>Below is an instruction that describes a task....</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>Generate a python script to perform this action.</td>\n      <td>Given a string, remove all the consecutive dup...</td>\n      <td>def remove_duplicates(string): \\n    result = ...</td>\n      <td>Below is an instruction that describes a task....</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>Write a python script to generates random numb...</td>\n      <td></td>\n      <td>def generate_random_divisible_number():\\n    i...</td>\n      <td>Below is an instruction that describes a task....</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>18607</th>\n      <td>Generate a loop in Python which iterates throu...</td>\n      <td></td>\n      <td>for value in list_of_values:\\n    print(value)</td>\n      <td>Below is an instruction that describes a task....</td>\n    </tr>\n    <tr>\n      <th>18608</th>\n      <td>Can you design a function in Python to sort a ...</td>\n      <td>tuples = [(\"b\", 0), (\"a\", 1), (\"c\", -1)]</td>\n      <td>def sort_tuple(tuples):\\n    # sort by 2nd ite...</td>\n      <td>Below is an instruction that describes a task....</td>\n    </tr>\n    <tr>\n      <th>18609</th>\n      <td>Generate a Python function to search an array ...</td>\n      <td>Array = [1, 5, 10, 15, 20], Target = 15</td>\n      <td>def search(array, target):\\n # Iterate over ar...</td>\n      <td>Below is an instruction that describes a task....</td>\n    </tr>\n    <tr>\n      <th>18610</th>\n      <td>Develop an HTTP API in Python to retrieve the ...</td>\n      <td></td>\n      <td>import requests\\nfrom bs4 import BeautifulSoup...</td>\n      <td>Below is an instruction that describes a task....</td>\n    </tr>\n    <tr>\n      <th>18611</th>\n      <td>Create a classification algorithm in Python to...</td>\n      <td></td>\n      <td># Import Python libraries\\nimport numpy as np\\...</td>\n      <td>Below is an instruction that describes a task....</td>\n    </tr>\n  </tbody>\n</table>\n<p>18612 rows × 4 columns</p>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"class CustomDataset(torch.utils.data.Dataset):\n    def __init__(self, dataframe):\n        self.dataframe = dataframe\n\n    def __len__(self):\n        return len(self.dataframe)\n\n    def __getitem__(self, idx):\n        row = self.dataframe.iloc[idx]\n        # Ensure each item is a 1D tensor\n        input_ids = row['input_ids'].squeeze()\n        attention_mask = row['attention_mask'].squeeze()\n        labels = row['labels'].squeeze()\n\n        # Debug: Print shapes\n#         print(f\"Input IDs shape: {input_ids.shape}\")\n#         print(f\"Attention Mask shape: {attention_mask.shape}\")\n#         print(f\"Labels shape: {labels.shape}\")\n\n        return {\n            'input_ids': input_ids,\n            'attention_mask': attention_mask,\n            'labels': labels\n        }\n","metadata":{"execution":{"iopub.status.busy":"2023-12-28T08:37:52.622245Z","iopub.execute_input":"2023-12-28T08:37:52.622916Z","iopub.status.idle":"2023-12-28T08:37:52.630066Z","shell.execute_reply.started":"2023-12-28T08:37:52.622888Z","shell.execute_reply":"2023-12-28T08:37:52.629213Z"},"trusted":true},"execution_count":15,"outputs":[]},{"cell_type":"code","source":"train_dataset = CustomDataset(train_df)\nval_dataset = CustomDataset(val_df)\ntest_dataset = CustomDataset(test_df)","metadata":{"execution":{"iopub.status.busy":"2023-12-28T08:37:52.631364Z","iopub.execute_input":"2023-12-28T08:37:52.632208Z","iopub.status.idle":"2023-12-28T08:37:52.646354Z","shell.execute_reply.started":"2023-12-28T08:37:52.632176Z","shell.execute_reply":"2023-12-28T08:37:52.645459Z"},"trusted":true},"execution_count":16,"outputs":[]},{"cell_type":"code","source":"test_dataset.dataframe[0:10]","metadata":{"execution":{"iopub.status.busy":"2023-12-27T09:09:47.494850Z","iopub.execute_input":"2023-12-27T09:09:47.495621Z","iopub.status.idle":"2023-12-27T09:09:47.706188Z","shell.execute_reply.started":"2023-12-27T09:09:47.495588Z","shell.execute_reply":"2023-12-27T09:09:47.705134Z"},"trusted":true},"execution_count":128,"outputs":[{"execution_count":128,"output_type":"execute_result","data":{"text/plain":"11487    {'input_ids': [[tensor(7255), tensor(19), tens...\n5598     {'input_ids': [[tensor(7255), tensor(19), tens...\n4186     {'input_ids': [[tensor(7255), tensor(19), tens...\n6746     {'input_ids': [[tensor(7255), tensor(19), tens...\n8581     {'input_ids': [[tensor(7255), tensor(19), tens...\n7284     {'input_ids': [[tensor(7255), tensor(19), tens...\n15641    {'input_ids': [[tensor(7255), tensor(19), tens...\n16597    {'input_ids': [[tensor(7255), tensor(19), tens...\n2493     {'input_ids': [[tensor(7255), tensor(19), tens...\n12696    {'input_ids': [[tensor(7255), tensor(19), tens...\ndtype: object"},"metadata":{}}]},{"cell_type":"markdown","source":"## Perform Parameter Efficient Fine-Tuning (PEFT)\n\n**Parameter Efficient Fine-Tuning (PEFT)** fine-tuning as opposed to \"full fine-tuning\" as we did above. PEFT is a form of instruction fine-tuning that is much more efficient than full fine-tuning.\n\nPEFT is a generic term that includes **Low-Rank Adaptation (LoRA)** and prompt tuning (which is NOT THE SAME as prompt engineering!). In most cases, when someone says PEFT, they typically mean LoRA. LoRA, at a very high level, allows the user to fine-tune their model using fewer compute resources (in some cases, a single GPU). After fine-tuning for a specific task, use case, or tenant with LoRA, the result is that the original LLM remains unchanged and a newly-trained “LoRA adapter” emerges. This LoRA adapter is much, much smaller than the original LLM - on the order of a single-digit % of the original LLM size (MBs vs GBs).  \n\nThat said, at inference time, the LoRA adapter needs to be reunited and combined with its original LLM to serve the inference request.  The benefit, however, is that many LoRA adapters can re-use the original LLM which reduces overall memory requirements when serving multiple tasks and use cases.","metadata":{}},{"cell_type":"code","source":"def print_number_of_trainable_model_parameters(model):\n    trainable_model_params = 0\n    all_model_params = 0\n    for _, param in model.named_parameters():\n        all_model_params += param.numel()\n        if param.requires_grad:\n            trainable_model_params += param.numel()\n    return f\"trainable model parameters: {trainable_model_params}\\nall model parameters: {all_model_params}\\npercentage of trainable model parameters: {100 * trainable_model_params / all_model_params:.2f}%\"","metadata":{"execution":{"iopub.status.busy":"2023-12-27T04:26:09.812605Z","iopub.execute_input":"2023-12-27T04:26:09.812949Z","iopub.status.idle":"2023-12-27T04:26:09.818241Z","shell.execute_reply.started":"2023-12-27T04:26:09.812920Z","shell.execute_reply":"2023-12-27T04:26:09.817370Z"},"trusted":true},"execution_count":21,"outputs":[]},{"cell_type":"markdown","source":"### Setup the PEFT/LoRA model for Fine-Tuning\n\nWe need to set up the PEFT/LoRA model for fine-tuning with a new layer/parameter adapter. Using PEFT/LoRA, you are freezing the underlying LLM and only training the adapter. Have a look at the LoRA configuration below. Note the rank (`r`) hyper-parameter, which defines the rank/dimension of the adapter to be trained.","metadata":{}},{"cell_type":"code","source":"from peft import LoraConfig, get_peft_model, TaskType\n\nmodel_name='google/flan-t5-base'\n\noriginal_model_instance = AutoModelForSeq2SeqLM.from_pretrained(model_name, torch_dtype=torch.bfloat16)\n\nlora_config = LoraConfig(\n    r=32,\n    lora_alpha=32,\n    target_modules=[\"q\", \"v\"],\n    lora_dropout=0.05,\n    bias=\"none\",\n    task_type=TaskType.SEQ_2_SEQ_LM\n)\n\npeft_model = get_peft_model(original_model_instance, lora_config)","metadata":{"execution":{"iopub.status.busy":"2023-12-27T04:26:10.293177Z","iopub.execute_input":"2023-12-27T04:26:10.293945Z","iopub.status.idle":"2023-12-27T04:26:12.592455Z","shell.execute_reply.started":"2023-12-27T04:26:10.293911Z","shell.execute_reply":"2023-12-27T04:26:12.591666Z"},"trusted":true},"execution_count":22,"outputs":[]},{"cell_type":"code","source":"print(print_number_of_trainable_model_parameters(peft_model))","metadata":{"execution":{"iopub.status.busy":"2023-12-27T04:26:12.594255Z","iopub.execute_input":"2023-12-27T04:26:12.594929Z","iopub.status.idle":"2023-12-27T04:26:12.604101Z","shell.execute_reply.started":"2023-12-27T04:26:12.594893Z","shell.execute_reply":"2023-12-27T04:26:12.603118Z"},"trusted":true},"execution_count":23,"outputs":[{"name":"stdout","text":"trainable model parameters: 3538944\nall model parameters: 251116800\npercentage of trainable model parameters: 1.41%\n","output_type":"stream"}]},{"cell_type":"code","source":"print(print_number_of_trainable_model_parameters(original_model))","metadata":{"execution":{"iopub.status.busy":"2023-12-27T04:26:12.604944Z","iopub.execute_input":"2023-12-27T04:26:12.605212Z","iopub.status.idle":"2023-12-27T04:26:12.619202Z","shell.execute_reply.started":"2023-12-27T04:26:12.605189Z","shell.execute_reply":"2023-12-27T04:26:12.618123Z"},"trusted":true},"execution_count":24,"outputs":[{"name":"stdout","text":"trainable model parameters: 247577856\nall model parameters: 247577856\npercentage of trainable model parameters: 100.00%\n","output_type":"stream"}]},{"cell_type":"markdown","source":"### Training PEFT adapter","metadata":{}},{"cell_type":"code","source":"# from transformers import TrainingArguments, Trainer\nimport time\n\noutput_dir = f'./text-to-code-training-{str(int(time.time()))}'\n\ntraining_args = TrainingArguments(\n    output_dir=output_dir,\n    per_device_train_batch_size=16,\n    learning_rate=5e-4,\n    per_device_eval_batch_size=16,\n    num_train_epochs=2,\n    logging_steps=10,\n    evaluation_strategy=\"epoch\",\n    save_strategy=\"epoch\",\n)\n\ntrainer = Trainer(\n    model=peft_model,\n    args=training_args,\n    train_dataset=train_dataset,\n    eval_dataset=val_dataset\n)\n\ntrainer.train()\n","metadata":{"execution":{"iopub.status.busy":"2023-12-27T04:26:18.963628Z","iopub.execute_input":"2023-12-27T04:26:18.964536Z","iopub.status.idle":"2023-12-27T04:59:52.032513Z","shell.execute_reply.started":"2023-12-27T04:26:18.964499Z","shell.execute_reply":"2023-12-27T04:59:52.031533Z"},"trusted":true},"execution_count":25,"outputs":[{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: Logging into wandb.ai. (Learn how to deploy a W&B server locally: https://wandb.me/wandb-server)\n\u001b[34m\u001b[1mwandb\u001b[0m: You can find your API key in your browser here: https://wandb.ai/authorize\n\u001b[34m\u001b[1mwandb\u001b[0m: Paste an API key from your profile and hit enter, or press ctrl+c to quit:","output_type":"stream"},{"output_type":"stream","name":"stdin","text":"  ········································\n"},{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Tracking run with wandb version 0.16.1"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Run data is saved locally in <code>/kaggle/working/wandb/run-20231227_042644-2396m6rl</code>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Syncing run <strong><a href='https://wandb.ai/srikanth-banda-team/huggingface/runs/2396m6rl' target=\"_blank\">dazzling-microwave-12</a></strong> to <a href='https://wandb.ai/srikanth-banda-team/huggingface' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View project at <a href='https://wandb.ai/srikanth-banda-team/huggingface' target=\"_blank\">https://wandb.ai/srikanth-banda-team/huggingface</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View run at <a href='https://wandb.ai/srikanth-banda-team/huggingface/runs/2396m6rl' target=\"_blank\">https://wandb.ai/srikanth-banda-team/huggingface/runs/2396m6rl</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='1630' max='1630' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [1630/1630 32:34, Epoch 2/2]\n    </div>\n    <table border=\"1\" class=\"dataframe\">\n  <thead>\n <tr style=\"text-align: left;\">\n      <th>Epoch</th>\n      <th>Training Loss</th>\n      <th>Validation Loss</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>1</td>\n      <td>0.773000</td>\n      <td>0.677718</td>\n    </tr>\n    <tr>\n      <td>2</td>\n      <td>0.873800</td>\n      <td>0.659362</td>\n    </tr>\n  </tbody>\n</table><p>"},"metadata":{}},{"execution_count":25,"output_type":"execute_result","data":{"text/plain":"TrainOutput(global_step=1630, training_loss=1.1585278470092024, metrics={'train_runtime': 2007.1219, 'train_samples_per_second': 12.982, 'train_steps_per_second': 0.812, 'total_flos': 9062654461083648.0, 'train_loss': 1.1585278470092024, 'epoch': 2.0})"},"metadata":{}}]},{"cell_type":"markdown","source":"## Checkpoint - Saving the finetuned LLM","metadata":{}},{"cell_type":"markdown","source":"Saving the model to the desired directory in Kaggel Output","metadata":{}},{"cell_type":"code","source":"# Save model and tokenizer\nmodel_save_path = \"/kaggle/working/Flan-T5-finetuned-sbanda/\"\ntokenizer.save_pretrained(model_save_path)\npeft_model.save_pretrained(model_save_path)\n","metadata":{"execution":{"iopub.status.busy":"2023-12-27T06:39:39.302899Z","iopub.execute_input":"2023-12-27T06:39:39.303924Z","iopub.status.idle":"2023-12-27T06:39:39.390321Z","shell.execute_reply.started":"2023-12-27T06:39:39.303883Z","shell.execute_reply":"2023-12-27T06:39:39.389331Z"},"trusted":true},"execution_count":73,"outputs":[]},{"cell_type":"markdown","source":"Zip the file to download all the files at once","metadata":{}},{"cell_type":"code","source":"!zip -r file.zip /kaggle/working/Flan-T5-finetuned-sbanda","metadata":{"execution":{"iopub.status.busy":"2023-12-27T06:42:21.807933Z","iopub.execute_input":"2023-12-27T06:42:21.808846Z","iopub.status.idle":"2023-12-27T06:42:23.816903Z","shell.execute_reply.started":"2023-12-27T06:42:21.808808Z","shell.execute_reply":"2023-12-27T06:42:23.815755Z"},"trusted":true},"execution_count":74,"outputs":[{"name":"stderr","text":"huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n","output_type":"stream"},{"name":"stdout","text":"  adding: kaggle/working/Flan-T5-finetuned-sbanda/ (stored 0%)\n  adding: kaggle/working/Flan-T5-finetuned-sbanda/README.md (deflated 66%)\n  adding: kaggle/working/Flan-T5-finetuned-sbanda/spiece.model (deflated 48%)\n  adding: kaggle/working/Flan-T5-finetuned-sbanda/tokenizer_config.json (deflated 95%)\n  adding: kaggle/working/Flan-T5-finetuned-sbanda/special_tokens_map.json (deflated 86%)\n  adding: kaggle/working/Flan-T5-finetuned-sbanda/adapter_config.json (deflated 50%)\n  adding: kaggle/working/Flan-T5-finetuned-sbanda/adapter_model.safetensors (deflated 22%)\n  adding: kaggle/working/Flan-T5-finetuned-sbanda/tokenizer.json (deflated 74%)\n","output_type":"stream"}]},{"cell_type":"markdown","source":"## Training in progress above","metadata":{}},{"cell_type":"markdown","source":"### Fine-Tune the Model with the Preprocessed Dataset","metadata":{}},{"cell_type":"code","source":"finetuned_model_path='/kaggle/input/my-model-files'\n\npeft_model = AutoModelForSeq2SeqLM.from_pretrained(finetuned_model_path, torch_dtype=torch.bfloat16)\ntokenizer = AutoTokenizer.from_pretrained(finetuned_model_path)","metadata":{"execution":{"iopub.status.busy":"2023-12-28T08:56:17.070672Z","iopub.execute_input":"2023-12-28T08:56:17.071562Z","iopub.status.idle":"2023-12-28T08:56:25.025048Z","shell.execute_reply.started":"2023-12-28T08:56:17.071529Z","shell.execute_reply":"2023-12-28T08:56:25.024127Z"},"trusted":true},"execution_count":20,"outputs":[]},{"cell_type":"code","source":"device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\npeft_model.to(device)  # Ensure the model is on the correct device","metadata":{"_kg_hide-output":true,"execution":{"iopub.status.busy":"2023-12-28T08:57:05.743950Z","iopub.execute_input":"2023-12-28T08:57:05.744334Z","iopub.status.idle":"2023-12-28T08:57:05.927073Z","shell.execute_reply.started":"2023-12-28T08:57:05.744306Z","shell.execute_reply":"2023-12-28T08:57:05.925961Z"},"collapsed":true,"jupyter":{"outputs_hidden":true},"trusted":true},"execution_count":25,"outputs":[{"execution_count":25,"output_type":"execute_result","data":{"text/plain":"T5ForConditionalGeneration(\n  (shared): Embedding(32128, 768)\n  (encoder): T5Stack(\n    (embed_tokens): Embedding(32128, 768)\n    (block): ModuleList(\n      (0): T5Block(\n        (layer): ModuleList(\n          (0): T5LayerSelfAttention(\n            (SelfAttention): T5Attention(\n              (q): lora.Linear(\n                (base_layer): Linear(in_features=768, out_features=768, bias=False)\n                (lora_dropout): ModuleDict(\n                  (default): Dropout(p=0.05, inplace=False)\n                )\n                (lora_A): ModuleDict(\n                  (default): Linear(in_features=768, out_features=32, bias=False)\n                )\n                (lora_B): ModuleDict(\n                  (default): Linear(in_features=32, out_features=768, bias=False)\n                )\n                (lora_embedding_A): ParameterDict()\n                (lora_embedding_B): ParameterDict()\n              )\n              (k): Linear(in_features=768, out_features=768, bias=False)\n              (v): lora.Linear(\n                (base_layer): Linear(in_features=768, out_features=768, bias=False)\n                (lora_dropout): ModuleDict(\n                  (default): Dropout(p=0.05, inplace=False)\n                )\n                (lora_A): ModuleDict(\n                  (default): Linear(in_features=768, out_features=32, bias=False)\n                )\n                (lora_B): ModuleDict(\n                  (default): Linear(in_features=32, out_features=768, bias=False)\n                )\n                (lora_embedding_A): ParameterDict()\n                (lora_embedding_B): ParameterDict()\n              )\n              (o): Linear(in_features=768, out_features=768, bias=False)\n              (relative_attention_bias): Embedding(32, 12)\n            )\n            (layer_norm): T5LayerNorm()\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n          (1): T5LayerFF(\n            (DenseReluDense): T5DenseGatedActDense(\n              (wi_0): Linear(in_features=768, out_features=2048, bias=False)\n              (wi_1): Linear(in_features=768, out_features=2048, bias=False)\n              (wo): Linear(in_features=2048, out_features=768, bias=False)\n              (dropout): Dropout(p=0.1, inplace=False)\n              (act): NewGELUActivation()\n            )\n            (layer_norm): T5LayerNorm()\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n        )\n      )\n      (1-11): 11 x T5Block(\n        (layer): ModuleList(\n          (0): T5LayerSelfAttention(\n            (SelfAttention): T5Attention(\n              (q): lora.Linear(\n                (base_layer): Linear(in_features=768, out_features=768, bias=False)\n                (lora_dropout): ModuleDict(\n                  (default): Dropout(p=0.05, inplace=False)\n                )\n                (lora_A): ModuleDict(\n                  (default): Linear(in_features=768, out_features=32, bias=False)\n                )\n                (lora_B): ModuleDict(\n                  (default): Linear(in_features=32, out_features=768, bias=False)\n                )\n                (lora_embedding_A): ParameterDict()\n                (lora_embedding_B): ParameterDict()\n              )\n              (k): Linear(in_features=768, out_features=768, bias=False)\n              (v): lora.Linear(\n                (base_layer): Linear(in_features=768, out_features=768, bias=False)\n                (lora_dropout): ModuleDict(\n                  (default): Dropout(p=0.05, inplace=False)\n                )\n                (lora_A): ModuleDict(\n                  (default): Linear(in_features=768, out_features=32, bias=False)\n                )\n                (lora_B): ModuleDict(\n                  (default): Linear(in_features=32, out_features=768, bias=False)\n                )\n                (lora_embedding_A): ParameterDict()\n                (lora_embedding_B): ParameterDict()\n              )\n              (o): Linear(in_features=768, out_features=768, bias=False)\n            )\n            (layer_norm): T5LayerNorm()\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n          (1): T5LayerFF(\n            (DenseReluDense): T5DenseGatedActDense(\n              (wi_0): Linear(in_features=768, out_features=2048, bias=False)\n              (wi_1): Linear(in_features=768, out_features=2048, bias=False)\n              (wo): Linear(in_features=2048, out_features=768, bias=False)\n              (dropout): Dropout(p=0.1, inplace=False)\n              (act): NewGELUActivation()\n            )\n            (layer_norm): T5LayerNorm()\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n        )\n      )\n    )\n    (final_layer_norm): T5LayerNorm()\n    (dropout): Dropout(p=0.1, inplace=False)\n  )\n  (decoder): T5Stack(\n    (embed_tokens): Embedding(32128, 768)\n    (block): ModuleList(\n      (0): T5Block(\n        (layer): ModuleList(\n          (0): T5LayerSelfAttention(\n            (SelfAttention): T5Attention(\n              (q): lora.Linear(\n                (base_layer): Linear(in_features=768, out_features=768, bias=False)\n                (lora_dropout): ModuleDict(\n                  (default): Dropout(p=0.05, inplace=False)\n                )\n                (lora_A): ModuleDict(\n                  (default): Linear(in_features=768, out_features=32, bias=False)\n                )\n                (lora_B): ModuleDict(\n                  (default): Linear(in_features=32, out_features=768, bias=False)\n                )\n                (lora_embedding_A): ParameterDict()\n                (lora_embedding_B): ParameterDict()\n              )\n              (k): Linear(in_features=768, out_features=768, bias=False)\n              (v): lora.Linear(\n                (base_layer): Linear(in_features=768, out_features=768, bias=False)\n                (lora_dropout): ModuleDict(\n                  (default): Dropout(p=0.05, inplace=False)\n                )\n                (lora_A): ModuleDict(\n                  (default): Linear(in_features=768, out_features=32, bias=False)\n                )\n                (lora_B): ModuleDict(\n                  (default): Linear(in_features=32, out_features=768, bias=False)\n                )\n                (lora_embedding_A): ParameterDict()\n                (lora_embedding_B): ParameterDict()\n              )\n              (o): Linear(in_features=768, out_features=768, bias=False)\n              (relative_attention_bias): Embedding(32, 12)\n            )\n            (layer_norm): T5LayerNorm()\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n          (1): T5LayerCrossAttention(\n            (EncDecAttention): T5Attention(\n              (q): lora.Linear(\n                (base_layer): Linear(in_features=768, out_features=768, bias=False)\n                (lora_dropout): ModuleDict(\n                  (default): Dropout(p=0.05, inplace=False)\n                )\n                (lora_A): ModuleDict(\n                  (default): Linear(in_features=768, out_features=32, bias=False)\n                )\n                (lora_B): ModuleDict(\n                  (default): Linear(in_features=32, out_features=768, bias=False)\n                )\n                (lora_embedding_A): ParameterDict()\n                (lora_embedding_B): ParameterDict()\n              )\n              (k): Linear(in_features=768, out_features=768, bias=False)\n              (v): lora.Linear(\n                (base_layer): Linear(in_features=768, out_features=768, bias=False)\n                (lora_dropout): ModuleDict(\n                  (default): Dropout(p=0.05, inplace=False)\n                )\n                (lora_A): ModuleDict(\n                  (default): Linear(in_features=768, out_features=32, bias=False)\n                )\n                (lora_B): ModuleDict(\n                  (default): Linear(in_features=32, out_features=768, bias=False)\n                )\n                (lora_embedding_A): ParameterDict()\n                (lora_embedding_B): ParameterDict()\n              )\n              (o): Linear(in_features=768, out_features=768, bias=False)\n            )\n            (layer_norm): T5LayerNorm()\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n          (2): T5LayerFF(\n            (DenseReluDense): T5DenseGatedActDense(\n              (wi_0): Linear(in_features=768, out_features=2048, bias=False)\n              (wi_1): Linear(in_features=768, out_features=2048, bias=False)\n              (wo): Linear(in_features=2048, out_features=768, bias=False)\n              (dropout): Dropout(p=0.1, inplace=False)\n              (act): NewGELUActivation()\n            )\n            (layer_norm): T5LayerNorm()\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n        )\n      )\n      (1-11): 11 x T5Block(\n        (layer): ModuleList(\n          (0): T5LayerSelfAttention(\n            (SelfAttention): T5Attention(\n              (q): lora.Linear(\n                (base_layer): Linear(in_features=768, out_features=768, bias=False)\n                (lora_dropout): ModuleDict(\n                  (default): Dropout(p=0.05, inplace=False)\n                )\n                (lora_A): ModuleDict(\n                  (default): Linear(in_features=768, out_features=32, bias=False)\n                )\n                (lora_B): ModuleDict(\n                  (default): Linear(in_features=32, out_features=768, bias=False)\n                )\n                (lora_embedding_A): ParameterDict()\n                (lora_embedding_B): ParameterDict()\n              )\n              (k): Linear(in_features=768, out_features=768, bias=False)\n              (v): lora.Linear(\n                (base_layer): Linear(in_features=768, out_features=768, bias=False)\n                (lora_dropout): ModuleDict(\n                  (default): Dropout(p=0.05, inplace=False)\n                )\n                (lora_A): ModuleDict(\n                  (default): Linear(in_features=768, out_features=32, bias=False)\n                )\n                (lora_B): ModuleDict(\n                  (default): Linear(in_features=32, out_features=768, bias=False)\n                )\n                (lora_embedding_A): ParameterDict()\n                (lora_embedding_B): ParameterDict()\n              )\n              (o): Linear(in_features=768, out_features=768, bias=False)\n            )\n            (layer_norm): T5LayerNorm()\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n          (1): T5LayerCrossAttention(\n            (EncDecAttention): T5Attention(\n              (q): lora.Linear(\n                (base_layer): Linear(in_features=768, out_features=768, bias=False)\n                (lora_dropout): ModuleDict(\n                  (default): Dropout(p=0.05, inplace=False)\n                )\n                (lora_A): ModuleDict(\n                  (default): Linear(in_features=768, out_features=32, bias=False)\n                )\n                (lora_B): ModuleDict(\n                  (default): Linear(in_features=32, out_features=768, bias=False)\n                )\n                (lora_embedding_A): ParameterDict()\n                (lora_embedding_B): ParameterDict()\n              )\n              (k): Linear(in_features=768, out_features=768, bias=False)\n              (v): lora.Linear(\n                (base_layer): Linear(in_features=768, out_features=768, bias=False)\n                (lora_dropout): ModuleDict(\n                  (default): Dropout(p=0.05, inplace=False)\n                )\n                (lora_A): ModuleDict(\n                  (default): Linear(in_features=768, out_features=32, bias=False)\n                )\n                (lora_B): ModuleDict(\n                  (default): Linear(in_features=32, out_features=768, bias=False)\n                )\n                (lora_embedding_A): ParameterDict()\n                (lora_embedding_B): ParameterDict()\n              )\n              (o): Linear(in_features=768, out_features=768, bias=False)\n            )\n            (layer_norm): T5LayerNorm()\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n          (2): T5LayerFF(\n            (DenseReluDense): T5DenseGatedActDense(\n              (wi_0): Linear(in_features=768, out_features=2048, bias=False)\n              (wi_1): Linear(in_features=768, out_features=2048, bias=False)\n              (wo): Linear(in_features=2048, out_features=768, bias=False)\n              (dropout): Dropout(p=0.1, inplace=False)\n              (act): NewGELUActivation()\n            )\n            (layer_norm): T5LayerNorm()\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n        )\n      )\n    )\n    (final_layer_norm): T5LayerNorm()\n    (dropout): Dropout(p=0.1, inplace=False)\n  )\n  (lm_head): Linear(in_features=768, out_features=32128, bias=False)\n)"},"metadata":{}}]},{"cell_type":"code","source":"original_model.to(device)","metadata":{"execution":{"iopub.status.busy":"2023-12-28T08:58:33.738730Z","iopub.execute_input":"2023-12-28T08:58:33.739686Z","iopub.status.idle":"2023-12-28T08:58:33.905307Z","shell.execute_reply.started":"2023-12-28T08:58:33.739649Z","shell.execute_reply":"2023-12-28T08:58:33.904318Z"},"collapsed":true,"jupyter":{"outputs_hidden":true},"trusted":true},"execution_count":31,"outputs":[{"execution_count":31,"output_type":"execute_result","data":{"text/plain":"T5ForConditionalGeneration(\n  (shared): Embedding(32128, 768)\n  (encoder): T5Stack(\n    (embed_tokens): Embedding(32128, 768)\n    (block): ModuleList(\n      (0): T5Block(\n        (layer): ModuleList(\n          (0): T5LayerSelfAttention(\n            (SelfAttention): T5Attention(\n              (q): Linear(in_features=768, out_features=768, bias=False)\n              (k): Linear(in_features=768, out_features=768, bias=False)\n              (v): Linear(in_features=768, out_features=768, bias=False)\n              (o): Linear(in_features=768, out_features=768, bias=False)\n              (relative_attention_bias): Embedding(32, 12)\n            )\n            (layer_norm): T5LayerNorm()\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n          (1): T5LayerFF(\n            (DenseReluDense): T5DenseGatedActDense(\n              (wi_0): Linear(in_features=768, out_features=2048, bias=False)\n              (wi_1): Linear(in_features=768, out_features=2048, bias=False)\n              (wo): Linear(in_features=2048, out_features=768, bias=False)\n              (dropout): Dropout(p=0.1, inplace=False)\n              (act): NewGELUActivation()\n            )\n            (layer_norm): T5LayerNorm()\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n        )\n      )\n      (1-11): 11 x T5Block(\n        (layer): ModuleList(\n          (0): T5LayerSelfAttention(\n            (SelfAttention): T5Attention(\n              (q): Linear(in_features=768, out_features=768, bias=False)\n              (k): Linear(in_features=768, out_features=768, bias=False)\n              (v): Linear(in_features=768, out_features=768, bias=False)\n              (o): Linear(in_features=768, out_features=768, bias=False)\n            )\n            (layer_norm): T5LayerNorm()\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n          (1): T5LayerFF(\n            (DenseReluDense): T5DenseGatedActDense(\n              (wi_0): Linear(in_features=768, out_features=2048, bias=False)\n              (wi_1): Linear(in_features=768, out_features=2048, bias=False)\n              (wo): Linear(in_features=2048, out_features=768, bias=False)\n              (dropout): Dropout(p=0.1, inplace=False)\n              (act): NewGELUActivation()\n            )\n            (layer_norm): T5LayerNorm()\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n        )\n      )\n    )\n    (final_layer_norm): T5LayerNorm()\n    (dropout): Dropout(p=0.1, inplace=False)\n  )\n  (decoder): T5Stack(\n    (embed_tokens): Embedding(32128, 768)\n    (block): ModuleList(\n      (0): T5Block(\n        (layer): ModuleList(\n          (0): T5LayerSelfAttention(\n            (SelfAttention): T5Attention(\n              (q): Linear(in_features=768, out_features=768, bias=False)\n              (k): Linear(in_features=768, out_features=768, bias=False)\n              (v): Linear(in_features=768, out_features=768, bias=False)\n              (o): Linear(in_features=768, out_features=768, bias=False)\n              (relative_attention_bias): Embedding(32, 12)\n            )\n            (layer_norm): T5LayerNorm()\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n          (1): T5LayerCrossAttention(\n            (EncDecAttention): T5Attention(\n              (q): Linear(in_features=768, out_features=768, bias=False)\n              (k): Linear(in_features=768, out_features=768, bias=False)\n              (v): Linear(in_features=768, out_features=768, bias=False)\n              (o): Linear(in_features=768, out_features=768, bias=False)\n            )\n            (layer_norm): T5LayerNorm()\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n          (2): T5LayerFF(\n            (DenseReluDense): T5DenseGatedActDense(\n              (wi_0): Linear(in_features=768, out_features=2048, bias=False)\n              (wi_1): Linear(in_features=768, out_features=2048, bias=False)\n              (wo): Linear(in_features=2048, out_features=768, bias=False)\n              (dropout): Dropout(p=0.1, inplace=False)\n              (act): NewGELUActivation()\n            )\n            (layer_norm): T5LayerNorm()\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n        )\n      )\n      (1-11): 11 x T5Block(\n        (layer): ModuleList(\n          (0): T5LayerSelfAttention(\n            (SelfAttention): T5Attention(\n              (q): Linear(in_features=768, out_features=768, bias=False)\n              (k): Linear(in_features=768, out_features=768, bias=False)\n              (v): Linear(in_features=768, out_features=768, bias=False)\n              (o): Linear(in_features=768, out_features=768, bias=False)\n            )\n            (layer_norm): T5LayerNorm()\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n          (1): T5LayerCrossAttention(\n            (EncDecAttention): T5Attention(\n              (q): Linear(in_features=768, out_features=768, bias=False)\n              (k): Linear(in_features=768, out_features=768, bias=False)\n              (v): Linear(in_features=768, out_features=768, bias=False)\n              (o): Linear(in_features=768, out_features=768, bias=False)\n            )\n            (layer_norm): T5LayerNorm()\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n          (2): T5LayerFF(\n            (DenseReluDense): T5DenseGatedActDense(\n              (wi_0): Linear(in_features=768, out_features=2048, bias=False)\n              (wi_1): Linear(in_features=768, out_features=2048, bias=False)\n              (wo): Linear(in_features=2048, out_features=768, bias=False)\n              (dropout): Dropout(p=0.1, inplace=False)\n              (act): NewGELUActivation()\n            )\n            (layer_norm): T5LayerNorm()\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n        )\n      )\n    )\n    (final_layer_norm): T5LayerNorm()\n    (dropout): Dropout(p=0.1, inplace=False)\n  )\n  (lm_head): Linear(in_features=768, out_features=32128, bias=False)\n)"},"metadata":{}}]},{"cell_type":"markdown","source":"### Fine-tuned output method\nDefining a function to generate output to the give prompt using fine-tuned model","metadata":{}},{"cell_type":"code","source":"def peft_model_generate_code(input_ids):\n    \n    peft_model_outputs = peft_model.generate(input_ids=input_ids, max_new_tokens=200, num_beams=1)  # Remove 'generation_config' and pass the parameters directly\n    peft_model_text_output = postprocess(tokenizer.decode(peft_model_outputs[0], skip_special_tokens=True))\n    \n    return peft_model_text_output","metadata":{"execution":{"iopub.status.busy":"2023-12-28T08:58:44.268510Z","iopub.execute_input":"2023-12-28T08:58:44.269386Z","iopub.status.idle":"2023-12-28T08:58:44.274106Z","shell.execute_reply.started":"2023-12-28T08:58:44.269351Z","shell.execute_reply":"2023-12-28T08:58:44.273268Z"},"trusted":true},"execution_count":32,"outputs":[]},{"cell_type":"code","source":"def base_model_generate_code(input_ids):\n    \n    original_output_ids = original_model.generate(input_ids=input_ids, generation_config=GenerationConfig(max_new_tokens=200, num_beams=1))\n    original_model_text_output = postprocess(tokenizer.decode(original_output_ids[0], skip_special_tokens=True))\n    \n    return original_model_text_output","metadata":{"execution":{"iopub.status.busy":"2023-12-28T08:58:44.642245Z","iopub.execute_input":"2023-12-28T08:58:44.642862Z","iopub.status.idle":"2023-12-28T08:58:44.648145Z","shell.execute_reply.started":"2023-12-28T08:58:44.642828Z","shell.execute_reply":"2023-12-28T08:58:44.647003Z"},"trusted":true},"execution_count":33,"outputs":[]},{"cell_type":"code","source":"def base_vs_peft(index):\n    \n    row = df.iloc[index]\n    \n    prompt = f\"\"\"\nBelow is an instruction that describes a task. Write a response that appropriately completes the request.\n\n### Instruction: \n{row['instruction']}\n\n### Input:\n{row['input']}\n\n### Response:\n\"\"\"\n    \n    input_ids = tokenizer(prompt, return_tensors=\"pt\").input_ids.to(device)\n    peft_output = peft_model_generate_code(input_ids)\n    base_output = base_model_generate_code(input_ids)\n    label = row['output']\n    \n    dash_line = '-'.join('' for x in range(100))\n    print(dash_line)\n    print(f'INPUT PROMPT:\\n{prompt}')\n    print(dash_line)\n    print(f'BASEMODEL GENERATION:\\n{base_output}\\n')\n    print(dash_line)\n    print(f'PEFT MODEL GENERATION:\\n{peft_output}')\n    print(dash_line)\n    print(f'LABEL:\\n{label}')","metadata":{"execution":{"iopub.status.busy":"2023-12-28T08:58:46.979132Z","iopub.execute_input":"2023-12-28T08:58:46.980277Z","iopub.status.idle":"2023-12-28T08:58:46.987757Z","shell.execute_reply.started":"2023-12-28T08:58:46.980236Z","shell.execute_reply":"2023-12-28T08:58:46.986758Z"},"trusted":true},"execution_count":34,"outputs":[]},{"cell_type":"code","source":"prompt = f\"\"\"\nBelow is an instruction that describes a task. Write a response that appropriately completes the request.\n\n### Instruction: \n{row['instruction']}\n\n### Input:\n{row['input']}\n\n### Response:\n\"\"\"\n\nprint(prompt)","metadata":{"execution":{"iopub.status.busy":"2023-12-28T08:57:14.922423Z","iopub.execute_input":"2023-12-28T08:57:14.923094Z","iopub.status.idle":"2023-12-28T08:57:14.968864Z","shell.execute_reply.started":"2023-12-28T08:57:14.923060Z","shell.execute_reply":"2023-12-28T08:57:14.967418Z"},"collapsed":true,"jupyter":{"outputs_hidden":true},"trusted":true},"execution_count":29,"outputs":[{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","Cell \u001b[0;32mIn[29], line 5\u001b[0m\n\u001b[1;32m      1\u001b[0m prompt \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\"\"\u001b[39m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;124mBelow is an instruction that describes a task. Write a response that appropriately completes the request.\u001b[39m\n\u001b[1;32m      3\u001b[0m \n\u001b[1;32m      4\u001b[0m \u001b[38;5;124m### Instruction: \u001b[39m\n\u001b[0;32m----> 5\u001b[0m \u001b[38;5;132;01m{\u001b[39;00m\u001b[43mrow\u001b[49m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124minstruction\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;132;01m}\u001b[39;00m\n\u001b[1;32m      6\u001b[0m \n\u001b[1;32m      7\u001b[0m \u001b[38;5;124m### Input:\u001b[39m\n\u001b[1;32m      8\u001b[0m \u001b[38;5;132;01m{\u001b[39;00mrow[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124minput\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;132;01m}\u001b[39;00m\n\u001b[1;32m      9\u001b[0m \n\u001b[1;32m     10\u001b[0m \u001b[38;5;124m### Response:\u001b[39m\n\u001b[1;32m     11\u001b[0m \u001b[38;5;124m\"\"\"\u001b[39m\n\u001b[1;32m     13\u001b[0m \u001b[38;5;28mprint\u001b[39m(prompt)\n","\u001b[0;31mNameError\u001b[0m: name 'row' is not defined"],"ename":"NameError","evalue":"name 'row' is not defined","output_type":"error"}]},{"cell_type":"markdown","source":"### Human evaluation of the model","metadata":{}},{"cell_type":"code","source":"base_vs_peft(4000)","metadata":{"execution":{"iopub.status.busy":"2023-12-28T08:58:53.225603Z","iopub.execute_input":"2023-12-28T08:58:53.225999Z","iopub.status.idle":"2023-12-28T08:58:57.524602Z","shell.execute_reply.started":"2023-12-28T08:58:53.225969Z","shell.execute_reply":"2023-12-28T08:58:57.523498Z"},"trusted":true},"execution_count":35,"outputs":[{"name":"stdout","text":"---------------------------------------------------------------------------------------------------\nINPUT PROMPT:\n\nBelow is an instruction that describes a task. Write a response that appropriately completes the request.\n\n### Instruction: \nDevelop a python program to print the character with the maximum frequency in a given string.\n\n### Input:\nsample_str = 'football'\n\n### Response:\n\n---------------------------------------------------------------------------------------------------\nBASEMODEL GENERATION:\nI'll try to find the 'football' in the str.\n\n---------------------------------------------------------------------------------------------------\nPEFT MODEL GENERATION:\ndef max_frequency(str):\n    max_frequency = 0\n    for i in range(len(str)):\n            if str[i] == 'football':\n            max_frequency += 1\n        return max_frequency\n\nprint(max_frequency)\n---------------------------------------------------------------------------------------------------\nLABEL:\ndef max_frequency_char(string):\n    char_freq = {}\n    for char in string:\n        if char in char_freq.keys():\n            char_freq[char] += 1 \n        else:\n            char_freq[char] = 1\n    max_freq = 0 \n    max_char = None\n    for char, freq in char_freq.items():\n        if freq > max_freq:\n            max_freq = freq\n            max_char = char \n    return max_char\n\nprint(max_frequency_char(sample_str))\n","output_type":"stream"}]},{"cell_type":"code","source":"df","metadata":{"execution":{"iopub.status.busy":"2023-12-27T07:32:49.811100Z","iopub.execute_input":"2023-12-27T07:32:49.811789Z","iopub.status.idle":"2023-12-27T07:32:49.829580Z","shell.execute_reply.started":"2023-12-27T07:32:49.811756Z","shell.execute_reply":"2023-12-27T07:32:49.828519Z"},"trusted":true},"execution_count":90,"outputs":[{"execution_count":90,"output_type":"execute_result","data":{"text/plain":"                                             instruction  \\\n0      Create a function to calculate the sum of a se...   \n1      Generate a Python code for crawling a website ...   \n2      Create a Python list comprehension to get the ...   \n3       Generate a python script to perform this action.   \n4      Write a python script to generates random numb...   \n...                                                  ...   \n18607  Generate a loop in Python which iterates throu...   \n18608  Can you design a function in Python to sort a ...   \n18609  Generate a Python function to search an array ...   \n18610  Develop an HTTP API in Python to retrieve the ...   \n18611  Create a classification algorithm in Python to...   \n\n                                                   input  \\\n0                                        [1, 2, 3, 4, 5]   \n1      website: www.example.com \\ndata to crawl: phon...   \n2                                                          \n3      Given a string, remove all the consecutive dup...   \n4                                                          \n...                                                  ...   \n18607                                                      \n18608           tuples = [(\"b\", 0), (\"a\", 1), (\"c\", -1)]   \n18609            Array = [1, 5, 10, 15, 20], Target = 15   \n18610                                                      \n18611                                                      \n\n                                                  output  \\\n0      # Python code\\ndef sum_sequence(sequence):\\n  ...   \n1      import requests\\nimport re\\n\\ndef crawl_websit...   \n2                     [x*x for x in [1, 2, 3, 5, 8, 13]]   \n3      def remove_duplicates(string): \\n    result = ...   \n4      def generate_random_divisible_number():\\n    i...   \n...                                                  ...   \n18607     for value in list_of_values:\\n    print(value)   \n18608  def sort_tuple(tuples):\\n    # sort by 2nd ite...   \n18609  def search(array, target):\\n # Iterate over ar...   \n18610  import requests\\nfrom bs4 import BeautifulSoup...   \n18611  # Import Python libraries\\nimport numpy as np\\...   \n\n                                                  prompt  \n0      Below is an instruction that describes a task....  \n1      Below is an instruction that describes a task....  \n2      Below is an instruction that describes a task....  \n3      Below is an instruction that describes a task....  \n4      Below is an instruction that describes a task....  \n...                                                  ...  \n18607  Below is an instruction that describes a task....  \n18608  Below is an instruction that describes a task....  \n18609  Below is an instruction that describes a task....  \n18610  Below is an instruction that describes a task....  \n18611  Below is an instruction that describes a task....  \n\n[18612 rows x 4 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>instruction</th>\n      <th>input</th>\n      <th>output</th>\n      <th>prompt</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>Create a function to calculate the sum of a se...</td>\n      <td>[1, 2, 3, 4, 5]</td>\n      <td># Python code\\ndef sum_sequence(sequence):\\n  ...</td>\n      <td>Below is an instruction that describes a task....</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>Generate a Python code for crawling a website ...</td>\n      <td>website: www.example.com \\ndata to crawl: phon...</td>\n      <td>import requests\\nimport re\\n\\ndef crawl_websit...</td>\n      <td>Below is an instruction that describes a task....</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>Create a Python list comprehension to get the ...</td>\n      <td></td>\n      <td>[x*x for x in [1, 2, 3, 5, 8, 13]]</td>\n      <td>Below is an instruction that describes a task....</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>Generate a python script to perform this action.</td>\n      <td>Given a string, remove all the consecutive dup...</td>\n      <td>def remove_duplicates(string): \\n    result = ...</td>\n      <td>Below is an instruction that describes a task....</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>Write a python script to generates random numb...</td>\n      <td></td>\n      <td>def generate_random_divisible_number():\\n    i...</td>\n      <td>Below is an instruction that describes a task....</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>18607</th>\n      <td>Generate a loop in Python which iterates throu...</td>\n      <td></td>\n      <td>for value in list_of_values:\\n    print(value)</td>\n      <td>Below is an instruction that describes a task....</td>\n    </tr>\n    <tr>\n      <th>18608</th>\n      <td>Can you design a function in Python to sort a ...</td>\n      <td>tuples = [(\"b\", 0), (\"a\", 1), (\"c\", -1)]</td>\n      <td>def sort_tuple(tuples):\\n    # sort by 2nd ite...</td>\n      <td>Below is an instruction that describes a task....</td>\n    </tr>\n    <tr>\n      <th>18609</th>\n      <td>Generate a Python function to search an array ...</td>\n      <td>Array = [1, 5, 10, 15, 20], Target = 15</td>\n      <td>def search(array, target):\\n # Iterate over ar...</td>\n      <td>Below is an instruction that describes a task....</td>\n    </tr>\n    <tr>\n      <th>18610</th>\n      <td>Develop an HTTP API in Python to retrieve the ...</td>\n      <td></td>\n      <td>import requests\\nfrom bs4 import BeautifulSoup...</td>\n      <td>Below is an instruction that describes a task....</td>\n    </tr>\n    <tr>\n      <th>18611</th>\n      <td>Create a classification algorithm in Python to...</td>\n      <td></td>\n      <td># Import Python libraries\\nimport numpy as np\\...</td>\n      <td>Below is an instruction that describes a task....</td>\n    </tr>\n  </tbody>\n</table>\n<p>18612 rows × 4 columns</p>\n</div>"},"metadata":{}}]},{"cell_type":"markdown","source":"##### Sum of two integers","metadata":{}},{"cell_type":"code","source":"row_input = \"\"\"Below is an instruction that describes a task. Write a response that appropriately completes the request.\n\n### Instruction: \nGenerate a python script to perform this action.\n\n### Input:\nGiven two integers, return the addition of the given integers.\n\nInput: \n\n### Response:\"\"\"","metadata":{"execution":{"iopub.status.busy":"2023-12-28T08:59:55.513271Z","iopub.execute_input":"2023-12-28T08:59:55.514080Z","iopub.status.idle":"2023-12-28T08:59:55.518395Z","shell.execute_reply.started":"2023-12-28T08:59:55.514046Z","shell.execute_reply":"2023-12-28T08:59:55.517367Z"},"trusted":true},"execution_count":39,"outputs":[]},{"cell_type":"code","source":"input_ids = tokenizer(row_input, return_tensors=\"pt\").input_ids.to(device)  # Move input tensors to the same device as the model\npeft_model_outputs = peft_model.generate(input_ids=input_ids, max_new_tokens=200, num_beams=1)  # Remove 'generation_config' and pass the parameters directly\npeft_model_text_output = postprocess(tokenizer.decode(peft_model_outputs[0], skip_special_tokens=True))","metadata":{"execution":{"iopub.status.busy":"2023-12-28T08:59:55.891395Z","iopub.execute_input":"2023-12-28T08:59:55.891798Z","iopub.status.idle":"2023-12-28T08:59:57.233938Z","shell.execute_reply.started":"2023-12-28T08:59:55.891770Z","shell.execute_reply":"2023-12-28T08:59:57.233094Z"},"trusted":true},"execution_count":40,"outputs":[]},{"cell_type":"code","source":"print(peft_model_text_output)","metadata":{"execution":{"iopub.status.busy":"2023-12-28T08:59:57.358586Z","iopub.execute_input":"2023-12-28T08:59:57.358942Z","iopub.status.idle":"2023-12-28T08:59:57.364107Z","shell.execute_reply.started":"2023-12-28T08:59:57.358914Z","shell.execute_reply":"2023-12-28T08:59:57.363057Z"},"trusted":true},"execution_count":41,"outputs":[{"name":"stdout","text":"def add_ints(a, b):\n    return a + b\n\nprint(add_ints(2, a))\n","output_type":"stream"}]},{"cell_type":"code","source":"row_input = \"\"\"Below is an instruction that describes a task. Write a response that appropriately completes the request.\n\n### Instruction: \nGenerate a python script to perform this action.\n\n### Input:\nThe Fibonacci numbers, commonly denoted F(n) form a sequence, called the Fibonacci sequence, such that each number is the sum of the two preceding ones, starting from 0 and 1. That is,\n\nF(0) = 0, F(1) = 1\nF(n) = F(n - 1) + F(n - 2), for n > 1.\nGiven n, calculate F(n).\n\n \n\nExample 1:\n\nInput: n = 2\nOutput: 1\nExplanation: F(2) = F(1) + F(0) = 1 + 0 = 1.\nExample 2:\n\nInput: n = 3\nOutput: 2\nExplanation: F(3) = F(2) + F(1) = 1 + 1 = 2.\nExample 3:\n\nInput: n = 4\nOutput: 3\nExplanation: F(4) = F(3) + F(2) = 2 + 1 = 3.\n \n\nConstraints:\n\n0 <= n <= 30\n\nInput: F(0) = a, F(1) = b\n\n### Response:\"\"\"","metadata":{"execution":{"iopub.status.busy":"2023-12-28T09:00:12.345210Z","iopub.execute_input":"2023-12-28T09:00:12.345586Z","iopub.status.idle":"2023-12-28T09:00:12.350668Z","shell.execute_reply.started":"2023-12-28T09:00:12.345557Z","shell.execute_reply":"2023-12-28T09:00:12.349658Z"},"trusted":true},"execution_count":42,"outputs":[]},{"cell_type":"code","source":"input_ids = tokenizer(row_input, return_tensors=\"pt\").input_ids.to(device)  # Move input tensors to the same device as the model\n","metadata":{"execution":{"iopub.status.busy":"2023-12-28T09:00:12.848352Z","iopub.execute_input":"2023-12-28T09:00:12.849237Z","iopub.status.idle":"2023-12-28T09:00:12.855650Z","shell.execute_reply.started":"2023-12-28T09:00:12.849204Z","shell.execute_reply":"2023-12-28T09:00:12.854579Z"},"trusted":true},"execution_count":43,"outputs":[]},{"cell_type":"code","source":"print(peft_model_generate_code(input_ids))","metadata":{"execution":{"iopub.status.busy":"2023-12-28T09:00:16.544138Z","iopub.execute_input":"2023-12-28T09:00:16.545045Z","iopub.status.idle":"2023-12-28T09:00:20.756456Z","shell.execute_reply.started":"2023-12-28T09:00:16.545014Z","shell.execute_reply":"2023-12-28T09:00:20.755619Z"},"trusted":true},"execution_count":44,"outputs":[{"name":"stdout","text":"def fibonacci(n):\n    f = 0\n    f = 1\n    for i in range(n):\n        if f % i == 0:\n            f += 1\n        f += 1\n        return f\n\nprint(f(n))\n","output_type":"stream"}]},{"cell_type":"code","source":"print(base_model_generate_code(input_ids))","metadata":{"execution":{"iopub.status.busy":"2023-12-27T08:48:24.373833Z","iopub.execute_input":"2023-12-27T08:48:24.374267Z","iopub.status.idle":"2023-12-27T08:48:24.792627Z","shell.execute_reply.started":"2023-12-27T08:48:24.374232Z","shell.execute_reply":"2023-12-27T08:48:24.791577Z"},"trusted":true},"execution_count":119,"outputs":[{"name":"stdout","text":"a, b = b, F(0) = a + b + 1\n","output_type":"stream"}]},{"cell_type":"markdown","source":"<a name='2.4'></a>\n### Evaluate the Model Quantitatively (with ROUGE Metric)\n\nThe [ROUGE metric](https://en.wikipedia.org/wiki/ROUGE_(metric)) helps quantify the validity of summarizations produced by models. It compares summarizations to a \"baseline\" summary which is usually created by a human. While not perfect, it does indicate the overall increase in summarization effectiveness that we have accomplished by fine-tuning.","metadata":{}},{"cell_type":"code","source":"rouge = evaluate.load('rouge')","metadata":{"tags":[],"execution":{"iopub.status.busy":"2023-12-28T09:00:27.439955Z","iopub.execute_input":"2023-12-28T09:00:27.440722Z","iopub.status.idle":"2023-12-28T09:00:30.009901Z","shell.execute_reply.started":"2023-12-28T09:00:27.440690Z","shell.execute_reply":"2023-12-28T09:00:30.008862Z"},"trusted":true},"execution_count":45,"outputs":[{"output_type":"display_data","data":{"text/plain":"Downloading builder script:   0%|          | 0.00/6.27k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"49df7fadce964799b50bb82bd369d478"}},"metadata":{}}]},{"cell_type":"markdown","source":"Generate the outputs for the sample of the test dataset (only 10 dialogues and summaries to save time), and save the results.","metadata":{}},{"cell_type":"code","source":"tokenized_test_data = test_df[0:10]\ntest_ids = [tokenized_test_data.index[i] for i,_ in enumerate(tokenized_test_data)]\n\noriginal_model_codes = []\npeft_model_codes = []\nlabel_codes = []\n\nfor index in test_ids:\n    \n    row = df.iloc[index]\n    prompt = f\"\"\"\n    Below is an instruction that describes a task. Write a response that appropriately completes the request.\n    \n    ### Instruction: \n    {row['instruction']}\n    \n    ### Input:\n    {row['input']}\n    \n    ### Response:\n    \"\"\"\n    \n    input_ids = tokenizer(prompt, return_tensors=\"pt\").input_ids.to(device)\n\n    original_model_text_output = base_model_generate_code(input_ids)\n    original_model_codes.append(original_model_text_output)\n\n    \n    peft_model_text_output = peft_model_generate_code(input_ids)\n    peft_model_codes.append(peft_model_text_output)\n    \n    label_codes.append(row['output'])\n    \nzipped_codes = list(zip(label_codes, original_model_codes, peft_model_codes))\n \nmetrics_df = pd.DataFrame(zipped_codes, columns = ['label_codes', 'original_model_codes', 'peft_model_codes'])\nmetrics_df","metadata":{"tags":[],"execution":{"iopub.status.busy":"2023-12-28T11:00:29.888676Z","iopub.execute_input":"2023-12-28T11:00:29.889548Z","iopub.status.idle":"2023-12-28T11:01:11.319429Z","shell.execute_reply.started":"2023-12-28T11:00:29.889515Z","shell.execute_reply":"2023-12-28T11:01:11.318455Z"},"trusted":true},"execution_count":113,"outputs":[{"execution_count":113,"output_type":"execute_result","data":{"text/plain":"                                         label_codes  \\\n0  class Animal:\\n    def __init__(self):\\n      ...   \n1            for i in range(2, 11, 2):\\n    print(i)   \n2  import random\\nimport string\\n\\ndef random_str...   \n3  def getMaxProfit(maxPrice, minPrice): \\n    # ...   \n4  for i in range(10): \\n    print(\"Perfect squar...   \n5  seen = set()\\nduplicates = []\\nfor item in my_...   \n6  def is_rotation(str1, str2):\\n    return len(s...   \n7  from collections import Counter \\n\\ndef most_f...   \n8  def sortDescending(numbers):\\n    for i in ran...   \n9                      largestNum = lambda a: max(a)   \n\n                                original_model_codes  \\\n0         I'll try to find a class that can do this.   \n1                                     I'll try that.   \n2                        I'll try to get it to work.   \n3   I'll try to find the maximum price of the stock.   \n4                        I'll try to get it to work.   \n5                 I'll try to find the correct list.   \n6  if 'hello' in 'lohel': print('NO') else: print...   \n7                               I'll try to find it.   \n8                                       [2, 3, 4, 5]   \n9  I'm sorry, I can't find the number of numbers ...   \n\n                                    peft_model_codes  \n0  def make_sound(animal):\\n    return ''.join(ma...  \n1  def print_even(numbers):\\n    for i in range(l...  \n2  import random\\n\\n# Create a random alphanumeri...  \n3  def max_profit(max_price):\\n    max_price = 12...  \n4  def print_perfect_squares(n):\\n    for i in ra...  \n5  def duplicate_values(my_list):\\n    return [[1...  \n6  def rotation(str, s):\\n    if s[0] == s[1]:\\n ...  \n7  def most_frequent_used_words(txt):\\n    for wo...  \n8  def sort_list(list):\\n    list = [6, 2, 12, 5]...  \n9  def largest_number(numbers):\\n    largest_numb...  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>label_codes</th>\n      <th>original_model_codes</th>\n      <th>peft_model_codes</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>class Animal:\\n    def __init__(self):\\n      ...</td>\n      <td>I'll try to find a class that can do this.</td>\n      <td>def make_sound(animal):\\n    return ''.join(ma...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>for i in range(2, 11, 2):\\n    print(i)</td>\n      <td>I'll try that.</td>\n      <td>def print_even(numbers):\\n    for i in range(l...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>import random\\nimport string\\n\\ndef random_str...</td>\n      <td>I'll try to get it to work.</td>\n      <td>import random\\n\\n# Create a random alphanumeri...</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>def getMaxProfit(maxPrice, minPrice): \\n    # ...</td>\n      <td>I'll try to find the maximum price of the stock.</td>\n      <td>def max_profit(max_price):\\n    max_price = 12...</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>for i in range(10): \\n    print(\"Perfect squar...</td>\n      <td>I'll try to get it to work.</td>\n      <td>def print_perfect_squares(n):\\n    for i in ra...</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>seen = set()\\nduplicates = []\\nfor item in my_...</td>\n      <td>I'll try to find the correct list.</td>\n      <td>def duplicate_values(my_list):\\n    return [[1...</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>def is_rotation(str1, str2):\\n    return len(s...</td>\n      <td>if 'hello' in 'lohel': print('NO') else: print...</td>\n      <td>def rotation(str, s):\\n    if s[0] == s[1]:\\n ...</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>from collections import Counter \\n\\ndef most_f...</td>\n      <td>I'll try to find it.</td>\n      <td>def most_frequent_used_words(txt):\\n    for wo...</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>def sortDescending(numbers):\\n    for i in ran...</td>\n      <td>[2, 3, 4, 5]</td>\n      <td>def sort_list(list):\\n    list = [6, 2, 12, 5]...</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>largestNum = lambda a: max(a)</td>\n      <td>I'm sorry, I can't find the number of numbers ...</td>\n      <td>def largest_number(numbers):\\n    largest_numb...</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"markdown","source":"Evaluate the models computing ROUGE metrics. Notice the improvement in the results!","metadata":{"tags":[]}},{"cell_type":"code","source":"original_model_results = rouge.compute(\n    predictions=original_model_codes,\n    references=label_codes,\n    use_aggregator=True,\n    use_stemmer=True,\n)\n\npeft_model_results = rouge.compute(\n    predictions=peft_model_codes,\n    references=label_codes,\n    use_aggregator=True,\n    use_stemmer=True,\n)\n\nprint('ORIGINAL MODEL:')\nprint(original_model_results)\nprint('PEFT MODEL:')\nprint(peft_model_results)","metadata":{"tags":[],"execution":{"iopub.status.busy":"2023-12-28T11:07:29.073272Z","iopub.execute_input":"2023-12-28T11:07:29.073714Z","iopub.status.idle":"2023-12-28T11:07:29.578477Z","shell.execute_reply.started":"2023-12-28T11:07:29.073682Z","shell.execute_reply":"2023-12-28T11:07:29.577520Z"},"trusted":true},"execution_count":114,"outputs":[{"name":"stdout","text":"ORIGINAL MODEL:\n{'rouge1': 0.09665653328153329, 'rouge2': 0.013333333333333332, 'rougeL': 0.07789601139601139, 'rougeLsum': 0.08996542346542347}\nPEFT MODEL:\n{'rouge1': 0.24173414899932089, 'rouge2': 0.08397068135836251, 'rougeL': 0.2040780441334244, 'rougeLsum': 0.2271730398437482}\n","output_type":"stream"}]},{"cell_type":"markdown","source":"The file `data/dialogue-summary-training-results.csv` contains a pre-populated list of all model results which you can use to evaluate on a larger section of data. Let's do that for each of the models:","metadata":{}},{"cell_type":"code","source":"prompts = [\n    f\"\"\"\n    Below is an instruction that describes a task. Write a response that appropriately completes the request.\n    \n    ### Instruction: \n    {row['instruction']}\n    \n    ### Input:\n    {row['input']}\n    \n    ### Response:\n    \"\"\"\n    for _, row in df.iloc[test_df.index].iterrows()\n]","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def generate_model_outputs_in_batches(model, prompts, BATCH_SIZE):\n    model.to(device)\n    outputs = []\n    for i in range(0, len(prompts), BATCH_SIZE):\n        batch_prompts = prompts[i:i + BATCH_SIZE]\n        input_ids = tokenizer(batch_prompts, padding=True, truncation=True, max_length=512, return_tensors=\"pt\").input_ids.to(device)\n        with torch.no_grad():\n            batch_output = model.generate(input_ids=input_ids, max_new_tokens=200, num_beams=1)\n            batch_output = [tokenizer.decode(ids, skip_special_tokens=True) for ids in batch_output]\n        outputs.extend(batch_output)\n    return outputs\nBATCH_SIZE = 20\n\n# Ensure that the prompts list has the correct number of elements\nassert len(prompts) == len(test_df), \"Number of prompts does not match the number of rows in test_df\"\n\n# Generate outputs for both models\noriginal_model_codes = generate_model_outputs_in_batches(original_model, prompts, BATCH_SIZE)\npeft_model_codes = generate_model_outputs_in_batches(peft_model, prompts, BATCH_SIZE)\n\n# Validate the length of the output lists\nassert len(original_model_codes) == len(test_df), \"Number of outputs from original_model does not match the number of rows in test_df\"\nassert len(peft_model_codes) == len(test_df), \"Number of outputs from peft_model does not match the number of rows in test_df\"\n\nprocess_output_code = lambda text : text.replace('four_spaces>', '    ').replace('newline>', '\\n').replace('tab>', '\\t')\npeft_model_codes = list(map(process_output_code,peft_model_codes))\n\nlabel_codes = [row['output'] for _, row in df.iloc[test_df.index].iterrows()]\n# Rest of the code remains the same\n","metadata":{"execution":{"iopub.status.busy":"2023-12-28T12:11:55.609069Z","iopub.execute_input":"2023-12-28T12:11:55.610064Z","iopub.status.idle":"2023-12-28T12:27:55.402666Z","shell.execute_reply.started":"2023-12-28T12:11:55.610029Z","shell.execute_reply":"2023-12-28T12:27:55.401578Z"},"trusted":true},"execution_count":127,"outputs":[]},{"cell_type":"code","source":"zipped_codes = list(zip(label_codes, original_model_codes, peft_model_codes))\n \nfull_metrics_df = pd.DataFrame(zipped_codes, columns = ['label_codes', 'original_model_codes', 'peft_model_codes'])","metadata":{"execution":{"iopub.status.busy":"2023-12-28T12:52:30.319688Z","iopub.execute_input":"2023-12-28T12:52:30.320106Z","iopub.status.idle":"2023-12-28T12:52:30.327112Z","shell.execute_reply.started":"2023-12-28T12:52:30.320076Z","shell.execute_reply":"2023-12-28T12:52:30.326193Z"},"trusted":true},"execution_count":159,"outputs":[]},{"cell_type":"code","source":"full_metrics_df","metadata":{"execution":{"iopub.status.busy":"2023-12-28T12:52:32.513997Z","iopub.execute_input":"2023-12-28T12:52:32.514681Z","iopub.status.idle":"2023-12-28T12:52:32.527286Z","shell.execute_reply.started":"2023-12-28T12:52:32.514646Z","shell.execute_reply":"2023-12-28T12:52:32.526209Z"},"trusted":true},"execution_count":160,"outputs":[{"execution_count":160,"output_type":"execute_result","data":{"text/plain":"                                            label_codes  \\\n0     class Animal:\\n    def __init__(self):\\n      ...   \n1               for i in range(2, 11, 2):\\n    print(i)   \n2     import random\\nimport string\\n\\ndef random_str...   \n3     def getMaxProfit(maxPrice, minPrice): \\n    # ...   \n4     for i in range(10): \\n    print(\"Perfect squar...   \n...                                                 ...   \n1930  def count_dups(arr):\\n  dt = {} \\n  count = 0 ...   \n1931  users = {} \\n\\ndef addUser(name, details): \\n ...   \n1932  class StringFormatter():\\n    def __init__(sel...   \n1933  class NeuralNetwork:\\n    def __init__(self, i...   \n1934  import sys\\n\\nif __name__ == '__main__':\\n arg...   \n\n                                   original_model_codes  \\\n0            I'll try to find a class that can do this.   \n1                                        I'll try that.   \n2                           I'll try to get it to work.   \n3      I'll try to find the maximum price of the stock.   \n4     I'll try to get it to print out the first 10 p...   \n...                                                 ...   \n1930                            I'm sorry to hear that.   \n1931                       I'll try to find a solution.   \n1932         I'll try to find a class that can do this.   \n1933  I'll try to get the neural network class to work.   \n1934                        I'm sorry, I can't do that.   \n\n                                       peft_model_codes  \n0     def make_sound(animal):\\n    return ''.join(ma...  \n1     def print_even(numbers):\\n    for i in range(l...  \n2     def random_alphanumeric_string(string):\\n    r...  \n3     def max_profit(max_price):\\n    max_price = 12...  \n4     def print_perfect_squares(n):\\n    for i in ra...  \n...                                                 ...  \n1930  def count_dups(arr): \\n    for x in arr: \\n   ...  \n1931  def store_data(data):\\n    return data\\n\\ndef ...  \n1932  def format_string(string):\\n    return string....  \n1933  def neural_network(input_size, number of outpu...  \n1934  import sys\\n\\ndef add_command_line(arr, sys.st...  \n\n[1935 rows x 3 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>label_codes</th>\n      <th>original_model_codes</th>\n      <th>peft_model_codes</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>class Animal:\\n    def __init__(self):\\n      ...</td>\n      <td>I'll try to find a class that can do this.</td>\n      <td>def make_sound(animal):\\n    return ''.join(ma...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>for i in range(2, 11, 2):\\n    print(i)</td>\n      <td>I'll try that.</td>\n      <td>def print_even(numbers):\\n    for i in range(l...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>import random\\nimport string\\n\\ndef random_str...</td>\n      <td>I'll try to get it to work.</td>\n      <td>def random_alphanumeric_string(string):\\n    r...</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>def getMaxProfit(maxPrice, minPrice): \\n    # ...</td>\n      <td>I'll try to find the maximum price of the stock.</td>\n      <td>def max_profit(max_price):\\n    max_price = 12...</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>for i in range(10): \\n    print(\"Perfect squar...</td>\n      <td>I'll try to get it to print out the first 10 p...</td>\n      <td>def print_perfect_squares(n):\\n    for i in ra...</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>1930</th>\n      <td>def count_dups(arr):\\n  dt = {} \\n  count = 0 ...</td>\n      <td>I'm sorry to hear that.</td>\n      <td>def count_dups(arr): \\n    for x in arr: \\n   ...</td>\n    </tr>\n    <tr>\n      <th>1931</th>\n      <td>users = {} \\n\\ndef addUser(name, details): \\n ...</td>\n      <td>I'll try to find a solution.</td>\n      <td>def store_data(data):\\n    return data\\n\\ndef ...</td>\n    </tr>\n    <tr>\n      <th>1932</th>\n      <td>class StringFormatter():\\n    def __init__(sel...</td>\n      <td>I'll try to find a class that can do this.</td>\n      <td>def format_string(string):\\n    return string....</td>\n    </tr>\n    <tr>\n      <th>1933</th>\n      <td>class NeuralNetwork:\\n    def __init__(self, i...</td>\n      <td>I'll try to get the neural network class to work.</td>\n      <td>def neural_network(input_size, number of outpu...</td>\n    </tr>\n    <tr>\n      <th>1934</th>\n      <td>import sys\\n\\nif __name__ == '__main__':\\n arg...</td>\n      <td>I'm sorry, I can't do that.</td>\n      <td>import sys\\n\\ndef add_command_line(arr, sys.st...</td>\n    </tr>\n  </tbody>\n</table>\n<p>1935 rows × 3 columns</p>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"print(full_metrics_df.iloc[300])","metadata":{"execution":{"iopub.status.busy":"2023-12-28T13:12:48.208188Z","iopub.execute_input":"2023-12-28T13:12:48.208552Z","iopub.status.idle":"2023-12-28T13:12:48.214216Z","shell.execute_reply.started":"2023-12-28T13:12:48.208523Z","shell.execute_reply":"2023-12-28T13:12:48.213274Z"},"trusted":true},"execution_count":166,"outputs":[{"name":"stdout","text":"label_codes             input_str = \"madamabcdcba\"\\n\\ndef find_palindr...\noriginal_model_codes    if'madamabcdcba' in input_str: print('abcdcba'...\npeft_model_codes        def find_palindromes(input_str):\\n    for i in...\nName: 300, dtype: object\n","output_type":"stream"}]},{"cell_type":"code","source":"print(len(original_model_codes),len(peft_model_codes),len(label_codes))","metadata":{"execution":{"iopub.status.busy":"2023-12-28T12:54:16.479799Z","iopub.execute_input":"2023-12-28T12:54:16.480561Z","iopub.status.idle":"2023-12-28T12:54:16.485722Z","shell.execute_reply.started":"2023-12-28T12:54:16.480525Z","shell.execute_reply":"2023-12-28T12:54:16.484720Z"},"trusted":true},"execution_count":161,"outputs":[{"name":"stdout","text":"1935 1935 1935\n","output_type":"stream"}]},{"cell_type":"code","source":"original_model_results = rouge.compute(\n    predictions=original_model_codes,\n    references=label_codes,\n    use_aggregator=True,\n    use_stemmer=True,\n)\n\npeft_model_results = rouge.compute(\n    predictions=peft_model_codes,\n    references=label_codes,\n    use_aggregator=True,\n    use_stemmer=True,\n)\n\nprint('ORIGINAL MODEL:')\nprint(original_model_results)\nprint('PEFT MODEL:')\nprint(peft_model_results)","metadata":{"tags":[],"execution":{"iopub.status.busy":"2023-12-28T12:54:20.198867Z","iopub.execute_input":"2023-12-28T12:54:20.199739Z","iopub.status.idle":"2023-12-28T12:54:33.798507Z","shell.execute_reply.started":"2023-12-28T12:54:20.199703Z","shell.execute_reply":"2023-12-28T12:54:33.797562Z"},"trusted":true},"execution_count":162,"outputs":[{"name":"stdout","text":"ORIGINAL MODEL:\n{'rouge1': 0.10800783354076518, 'rouge2': 0.042290874296053924, 'rougeL': 0.10011801779543442, 'rougeLsum': 0.10543333385880252}\nPEFT MODEL:\n{'rouge1': 0.3073409456381371, 'rouge2': 0.11732385399253284, 'rougeL': 0.27339907243217143, 'rougeLsum': 0.3014207526081562}\n","output_type":"stream"}]},{"cell_type":"markdown","source":"The results show substantial improvement in all ROUGE metrics:","metadata":{"tags":[]}},{"cell_type":"code","source":"print(\"Absolute percentage improvement of PEFT MODEL over ACTUAL LABEL CODE\")\n\nimprovement = (np.array(list(peft_model_results.values())) - np.array(list(original_model_results.values())))\nfor key, value in zip(peft_model_results.keys(), improvement):\n    print(f'{key}: {value*100:.2f}%')","metadata":{"tags":[],"execution":{"iopub.status.busy":"2023-12-28T12:55:41.479024Z","iopub.execute_input":"2023-12-28T12:55:41.479767Z","iopub.status.idle":"2023-12-28T12:55:41.485895Z","shell.execute_reply.started":"2023-12-28T12:55:41.479736Z","shell.execute_reply":"2023-12-28T12:55:41.484930Z"},"trusted":true},"execution_count":164,"outputs":[{"name":"stdout","text":"Absolute percentage improvement of PEFT MODEL over ACTUAL LABEL CODE\nrouge1: 19.93%\nrouge2: 7.50%\nrougeL: 17.33%\nrougeLsum: 19.60%\n","output_type":"stream"}]},{"cell_type":"markdown","source":"## Challenges faced","metadata":{}},{"cell_type":"markdown","source":"1. Assesing feasibility of loading/training a model with the available compute resources.\n    - <u>Resolution</u>: Selected BFLOAT16 to load the model in reduced precision, thus requring less memory. Hence requiring 2 bytes per parameter instead of 4 bytes. For a 0.25B parameters model like flanT5, we need **0.5GB to load** the model and **10GB memory to train**.\n        - <u>Available compute resources:</u>\n            - Session: 12 hours\n            - Disk: 73.1GB\n            - CPU: 29GB\n            - GPU Memory: 15.9GB\n2. Data processing for training:\n    - Writing the `tokenize_function` to craft the prompts in the desired way.\n    - crafting the generated outputs to include escape characters as we are ignoring special characters\n   ","metadata":{}}]}